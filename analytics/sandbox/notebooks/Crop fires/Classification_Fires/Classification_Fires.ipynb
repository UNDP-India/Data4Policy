{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fire Classification\n",
    "\n",
    "This file contains a function which can classify the geographic setting of the fire in an area. <br>\n",
    "Using the Land Use Land Cover data this script classifies if the fire was in a cropped area, around trees, flooded vegetation, etc. <br>\n",
    "The useful data here comes from the fires in the agricultural areas. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you experience module related import errors <br>\n",
    "\n",
    "Use this to install the necessary libraries: \n",
    ">!pip install geopandas pandas rasterio rasterstats matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Classification_Fires.ipynb',\n",
       " 'fires_data_classified.csv',\n",
       " 'fires_data_classified.geojson',\n",
       " 'fire_classification_function.ipynb',\n",
       " 'telanganafire.geojson']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data\n",
    "\n",
    "This code imports a CSV file called _'telangana_fires.csv'_ containing information from the fires in Telangana between 2015 and 2018 and stores it in the variable _'fire_data'_. \n",
    "\n",
    "It also imports three geojson files: _'TL_state_shapefile_for_clip.geojson'_, _'TS_district_boundary.json'_, and _'telanganafire.geojson'_, \n",
    "and stores them in the variables _'telangana_shape'_, _'district_boundaries'_, and _'fires_2021'_, respectively. \n",
    "We are using Geopandas to read geojson files. \n",
    "\n",
    "Here, fire_data contains parameters such as acq_date (date of recording), acq_time (time of recording), satellite (name/ type of satellite), instrument (instrument used), confidence (certainity that it is fire), bright_t31 (brightness) frp (fire radiative power) daynight (day/night). \n",
    "Telangana shapefiles contains geographic boundaries of telangana and it's districts, and fire contains data of fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data = pd.read_csv('../../../geospatial_internship/datasets/telangana_fires.csv')\n",
    "telangana_shape = gpd.read_file('../../../../../src/data_preprocessing/base_geojson/TL_state_shapefile_for_clip.geojson')\n",
    "\n",
    "district_boundaries = gpd.read_file('../../../../../src/data_preprocessing/base_geojson/TS_district_boundary.json')\n",
    "\n",
    "fires_2021 = gpd.read_file('telanganafire.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data['acq_date'] = pd.to_datetime(fire_data['acq_date'])\n",
    "fires_2021['acq_date'] = pd.to_datetime(fires_2021['acq_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing and classification\n",
    "\n",
    "We read the fire data, classify it into a geographical setting (farm, forest, urban, etc.) using LULC data, then we see if there are trees around the fire areas, which helps us understand the nature of the surrounding setting better. The obtained data is then assigned to the closest mandal We read the fire data, classify it into a geographical setting (farm, forest, urban, etc.) The resulting data is saved to a new file to be used for further use/reference.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create geodataframe from the data\n",
    "geo_fire_data = gpd.GeoDataFrame(fire_data,geometry = gpd.points_from_xy(fire_data.longitude,fire_data.latitude), crs = {'init': 'epsg:4326'}) \n",
    "\n",
    "#Make sure the\n",
    "geo_fire_data['geometry'] = geo_fire_data['geometry'].geometry.to_crs(epsg = 4326)\n",
    "district_boundaries['geometry'] = district_boundaries['geometry'].geometry.to_crs(epsg = 4326)\n",
    "\n",
    "#Combine fires from 2021 with the rest\n",
    "geo_fire_data = geo_fire_data.append(fires_2021)\n",
    "geo_fire_data['fireID'] = [a for a in range(0, len(geo_fire_data))]\n",
    "\n",
    "polygons = []\n",
    "\n",
    "#-------create a buffer of square of 1km size using buffer function from shapely-----#\n",
    "\n",
    "for i in geo_fire_data.geometry:\n",
    "    p1 = i\n",
    "    buffer = p1.buffer(0.004504505, cap_style = 3)         #500m = 0.004504505 and cap_style 3 is square box of same of 1km side length\n",
    "    polygons.append(buffer)\n",
    "\n",
    "#create a new column in GeoDataFrame newdf and dump polygon buffer of respective point values\n",
    "geo_fire_data['geometry buffered'] = polygons \n",
    "\n",
    "geo_fire_data['acq_date'] =  pd.to_datetime(geo_fire_data['acq_date'])\n",
    "geo_fire_data['year'] = (geo_fire_data['acq_date']).dt.year\n",
    "\n",
    "geo_fire_data = geo_fire_data[geo_fire_data['year']<2022]\n",
    "geo_fire_data\n",
    "\n",
    "LULC_location = '../../../../../src/data_preprocessing/LULC/'\n",
    "df = pd.DataFrame(columns=geo_fire_data.columns)\n",
    "\n",
    "for a in geo_fire_data['year'].unique():\n",
    "    year = a\n",
    "    year_data = geo_fire_data[geo_fire_data['year'] == year]\n",
    "    if (year==2015) | (year == 2016):\n",
    "        tiff = LULC_location+'01-01-2017.tif'\n",
    "    else:\n",
    "        tiff = LULC_location+'01-01-'+str(year)+'.tif'\n",
    "    lulc = rasterio.open(tiff, mode = 'r')\n",
    "    lulc_array = lulc.read(1) # landuse corresponding to each rasterpixel, so we extracted the pixel values from the raster\n",
    "    # affine: 1: corresponds to the width of each pixel, 2: row rotation, 3: x-coordinate of the upper left pixel, 4: column rotation, 5: height of each pixel, 6: y-coordinate of the upper left pixel\n",
    "    affine = lulc.transform\n",
    "    cmap = {1: 'Water', 2: 'Trees', 4: 'Flooded Vegetation', 5: 'Crops', 7: 'Built Area', 8: 'Bare Ground', 9: 'Snow/Ice', 10: 'Clouds', 11: 'Rangeland'}\n",
    "    year_data['Land use'] = 0\n",
    "    year_data['Trees Around'] = 0\n",
    "\n",
    "    for i in range(0, len(year_data)):\n",
    "        test = zonal_stats(year_data['geometry'].iloc[i], lulc_array, affine = affine, geojson_out = True, stats = 'majority', nodata = lulc.nodata, categorical=True, category_map = cmap, all_touched=True)\n",
    "        try: \n",
    "            year_data['Land use'].iloc[i] = test[0]['properties']['majority']\n",
    "        except:\n",
    "            year_data['Land use'].iloc[i] = 'unknown'\n",
    "\n",
    "    for i in range(0, len(year_data)):\n",
    "        test = zonal_stats(year_data['geometry buffered'].iloc[i], lulc_array, affine = affine, geojson_out = True, stats = 'majority', nodata = lulc.nodata, categorical=True, category_map = cmap, all_touched=True)\n",
    "\n",
    "        if 'Trees' in list(test[0]['properties'].keys()):\n",
    "            year_data['Trees Around'].iloc[i]=1\n",
    "        else:\n",
    "            year_data['Trees Around'].iloc[i]=0\n",
    "\n",
    "    \n",
    "    df = pd.concat([df, year_data], axis = 0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['agricultural'] = 0\n",
    "df['agricultural strict'] = 0\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    if (df['Land use'].iloc[i] == 5) | (df['Land use'].iloc[i] == 4) :\n",
    "        df['agricultural'].iloc[i] = 1\n",
    "    if ((df['Land use'].iloc[i] == 5) | (df['Land use'].iloc[i] == 4)) & (df['Trees Around'].iloc[i]==0):\n",
    "        df['agricultural strict'].iloc[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['fireID', 'latitude', 'longitude', 'brightness', 'scan', 'track',\n",
    "       'acq_date', 'acq_time', 'satellite', 'instrument', 'confidence',\n",
    "       'version', 'bright_t31', 'frp', 'daynight', 'type', 'geometry','agricultural', 'agricultural strict']].to_csv('fires_data_classified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.GeoDataFrame(df,geometry = df.geometry, crs = {'init': 'epsg:4326'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['fireID', 'latitude', 'longitude', 'brightness', 'scan', 'track',\n",
    "       'acq_date', 'acq_time', 'satellite', 'instrument', 'confidence',\n",
    "       'version', 'bright_t31', 'frp', 'daynight', 'type', 'geometry','agricultural', 'agricultural strict']].to_file('fires_data_classified.geojson', driver=\"GeoJSON\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification (Using Shivangs Approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : https://github.com/luckyw0w/Data4Policy/tree/main/Geospatial%20Data%20Science%20Internship/ShivangPandey\n",
    "\n",
    "So, the buffer function of geopandas (based on the shapely library) is to create a buffer polygon around a point. The first parameter of the buffer is to tell length in the degree to mark the point in a square pixel and 'cap_style' to tell the type of polygon. here 'cap_style = 3' means square polygon for buffer point. \n",
    "\n",
    "We need to create a polygon, because MODIS Thermal Anomalies & Fire Daily data is calculated on 1km resolution and given esri LULC data is at 10m resolution and we can say it like that 1 pixel of MODIS fire data should be as big as 10000 pixels of LULC map.\n",
    "How we are going to use that? by creating a polygon as a size of 10000 pixels of LULC map.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : https://www.arcgis.com/home/item.html?id=d6642f8a4f6d4685a24ae2dc0c73d4ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 135.38010573387146 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#os.chdir('c:\\\\Users\\\\Jesse\\\\OneDrive\\\\Documenten\\\\Master BAOR\\\\Thesis\\\\GitHub\\\\dicra\\\\analytics\\\\notebooks\\\\crop_fires')\n",
    "tiff = '../../../../../src/data_preprocessing/LULC/01-01-2017.tif'\n",
    "    \n",
    "data = geo_fire_data\n",
    "data['index'] = data.index\n",
    "\n",
    "#------------------Checking probability in mosaic tiff file----------------------#\n",
    "import time                                      #to calculate time taken to run the model\n",
    "start_time = time.time()                         #start time of the program\n",
    "\n",
    "index_list = []                               #declaring empty to get corresponding id of fire point\n",
    "flag_list = []                                #empty list to store class of corresponding fire points based polygon\n",
    "    \n",
    "for j in range(len(data)):                #iterating all rows of dataframe to get point info\n",
    "\n",
    "    stats = zonal_stats(data.iloc[j].geometry, tiff, stats=\"*\", categorical=True)         #getting statistics from the raster point \n",
    "    i = stats[0]                                                                          #storing statsistical dictionary in a value\n",
    "    if i['count'] != 0:                                                                   #check if polygon is within the tiff file or not\n",
    "        index = data.iloc[j]['index']                                                     #get id of polygon\n",
    "        index_list.append(index)                                                          #store id in a list\n",
    "        if (5 in i) or (4 in i): \n",
    "            #print(i)                                                         #check if crop class or flooded vegitation is in polygon region or not\n",
    "            flag = 1                                                                      #Mark whether occurence is in crop field\n",
    "        else:\n",
    "            flag = 0                                                                      # if crop class is not in polygon, return 0 pixels\n",
    "        flag_list.append(flag)                                                            #store class value in a list\n",
    "        \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))                                  #print total time taken to run code \n",
    "\n",
    "#dictionary created wth fireID and class (1,0)\n",
    "id_class = {key: value for key, value in zip(index_list, flag_list)}\n",
    "\n",
    "#creating tuple of each key and  value pair\n",
    "data_items = id_class.items()                                                \n",
    "#dumping all tuples in a list\n",
    "data_list = list(data_items)\n",
    "\n",
    "#creating DataFrame with id and class values\n",
    "class_df = pd.DataFrame(data_list, columns= ['fireID','class (1,0)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_fire_data['agricultural'] = class_df['class (1,0)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_fire_data[['fireID', 'latitude', 'longitude', 'brightness', 'scan', 'track',\n",
    "       'acq_date', 'acq_time', 'satellite', 'instrument', 'confidence',\n",
    "       'version', 'bright_t31', 'frp', 'daynight', 'type', 'geometry','agricultural']].to_csv('fires_data_classified.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
