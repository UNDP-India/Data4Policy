{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of news articles:  100\n"
     ]
    }
   ],
   "source": [
    "#import what we need\n",
    "from requests_html import HTMLSession\n",
    "session = HTMLSession()\n",
    "import pandas as pd\n",
    "import newspaper\n",
    "import json\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "#use session to get the page\n",
    "r = session.get('https://news.google.com/search?q=stubble%20burning%20in%20Telangana%20when%3A1y&hl=en-IN&gl=IN&ceid=IN%3Aen')  #agriculture telangana\n",
    "\n",
    "#render the html, sleep=1 to give it a second to finish before moving on. scrolldown= how many times to page down on the browser, to get more results. 5 was a good number here\n",
    "#r.html.render(sleep=1, scrolldown=5)     # ----------------------# THIS LINE WAS FETCHING ME ERROR IN JUPYTER NOTEBOOK\n",
    "\n",
    "#find all the articles by using inspect element and create blank list\n",
    "articles = r.html.find('article')\n",
    "newslist = []\n",
    "\n",
    "#loop through each article to find the title and link. try and except as repeated articles from other sources have different h tags.\n",
    "for item in articles:\n",
    "    try:\n",
    "        newsitem = item.find('h3', first=True)\n",
    "        title = newsitem.text\n",
    "        link = newsitem.absolute_links\n",
    "        newsarticle = {\n",
    "            'title': title,\n",
    "            'link': link \n",
    "        }\n",
    "        newslist.append(newsarticle)\n",
    "    except:\n",
    "       pass\n",
    "\n",
    "#print the length of the list\n",
    "print('List of news articles: ',len(newslist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe of newslist and link\n",
    "df = pd.DataFrame(newslist)\n",
    "\n",
    "\n",
    "#Scrape the list of article dictionary from news list\n",
    "news_articles = []\n",
    "for i in df.link:\n",
    "    try:\n",
    "        url = list(i)[0]\n",
    "        article = newspaper.Article(url=url, language='en')\n",
    "        article.download()\n",
    "        article.parse()\n",
    "\n",
    "        article ={\n",
    "            \"title\": str(article.title),\n",
    "            \"text\": str(article.text),\n",
    "            \"authors\": article.authors,\n",
    "            \"published_date\": str(article.publish_date),\n",
    "            \"top_image\": str(article.top_image),\n",
    "            \"videos\": article.movies,\n",
    "            \"keywords\": article.keywords,\n",
    "            \"summary\": str(article.summary)\n",
    "        }\n",
    "        news_articles.append(article)\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert list of news articles into dataframe with all scraped information\n",
    "news = pd.DataFrame(news_articles)\n",
    "text = news.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read geodataframe for mandal and district names to search in news articles\n",
    "gdf = gpd.read_file('../DPPD/data/TSDM/Mandal_Boundary.shp')\n",
    "mandal = list(gdf.Mandal_Nam.unique()) #unique mandals\n",
    "dist = list(gdf.Dist_Name.unique())    #unique districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access list of mandal mentione in each article\n",
    "\n",
    "keyword_mandal = []\n",
    "mandal_list = []\n",
    "\n",
    "for text in  news.text:\n",
    "    for i in range(0, len(mandal)):\n",
    "        if mandal[i] in text:\n",
    "            keyword_mandal.append(mandal[i])\n",
    "    # insert the list to the set\n",
    "        list_set = set(keyword_mandal)\n",
    "    # convert the set to the list\n",
    "        unique_list = (list(list_set))\n",
    "    mandal_list.append(unique_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access list of district mentione in each article\n",
    "keyword_dist = []\n",
    "dist_list = []\n",
    "for text in  news.text:\n",
    "    for i in range(0, len(dist)):\n",
    "        if dist[i] in text:\n",
    "            keyword_dist.append(dist[i])\n",
    "    # insert the list to the set\n",
    "        list_set = set(keyword_dist)\n",
    "    # convert the set to the list\n",
    "        unique_list = (list(list_set))\n",
    "    dist_list.append(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add mandal and districts to news dataframe\n",
    "news['Mandals'] = mandal_list\n",
    "news['Districts'] = dist_list\n",
    "\n",
    "#convert full news dataframe to csv\n",
    "news.to_csv('news_full.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe with few columns\n",
    "news1 = news[['title','Mandals','Districts','published_date']]\n",
    "news1.to_csv('news.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news2 = news1[news1['Districts'] != '[]']\n",
    "len(news1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "newslistdf = pd.DataFrame(newslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newslistdf.to_csv('newslist.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import newspaper\n",
    "import geopandas as gpd\n",
    "\n",
    "from GoogleNews import GoogleNews\n",
    "googlenews = GoogleNews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 429: Too Many Requests\n"
     ]
    }
   ],
   "source": [
    "googlenews = GoogleNews()\n",
    "googlenews.headers = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Cafari/537.36'\n",
    "googlenews = GoogleNews(start='01/12/2022',end='07/12/2022')\n",
    "googlenews.search('agriculture Khammam')\n",
    "   \n",
    "result=googlenews.result()\n",
    "df=pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "dicra/analytics/sandbox/notebooks/SoilMoistureDeviance/Results/: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mfiona/_shim.pyx:83\u001b[0m, in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: dicra/analytics/sandbox/notebooks/SoilMoistureDeviance/Results/: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Read geodataframe for mandal and district names to search in news articles\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m gdf \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdicra/analytics/sandbox/notebooks/SoilMoistureDeviance/Results/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m mandal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(gdf\u001b[38;5;241m.\u001b[39mMandal_Nam\u001b[38;5;241m.\u001b[39munique()) \u001b[38;5;66;03m#unique mandals\u001b[39;00m\n\u001b[1;32m      6\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(gdf\u001b[38;5;241m.\u001b[39mDist_Name\u001b[38;5;241m.\u001b[39munique())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/geopandas/io/file.py:259\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m     path_or_bytes \u001b[39m=\u001b[39m filename\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfiona\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mreturn\u001b[39;00m _read_file_fiona(\n\u001b[1;32m    260\u001b[0m         path_or_bytes, from_bytes, bbox\u001b[39m=\u001b[39;49mbbox, mask\u001b[39m=\u001b[39;49mmask, rows\u001b[39m=\u001b[39;49mrows, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    261\u001b[0m     )\n\u001b[1;32m    262\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyogrio\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    263\u001b[0m     \u001b[39mreturn\u001b[39;00m _read_file_pyogrio(\n\u001b[1;32m    264\u001b[0m         path_or_bytes, bbox\u001b[39m=\u001b[39mbbox, mask\u001b[39m=\u001b[39mmask, rows\u001b[39m=\u001b[39mrows, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    265\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/geopandas/io/file.py:303\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     reader \u001b[39m=\u001b[39m fiona\u001b[39m.\u001b[39mopen\n\u001b[1;32m    302\u001b[0m \u001b[39mwith\u001b[39;00m fiona_env():\n\u001b[0;32m--> 303\u001b[0m     \u001b[39mwith\u001b[39;00m reader(path_or_bytes, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m features:\n\u001b[1;32m    304\u001b[0m         crs \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mcrs_wkt\n\u001b[1;32m    305\u001b[0m         \u001b[39m# attempt to get EPSG code\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fiona/env.py:408\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    406\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    407\u001b[0m     \u001b[39mif\u001b[39;00m local\u001b[39m.\u001b[39m_env:\n\u001b[0;32m--> 408\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    409\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fiona/__init__.py:264\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     path \u001b[39m=\u001b[39m parse_path(fp)\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 264\u001b[0m     c \u001b[39m=\u001b[39m Collection(path, mode, driver\u001b[39m=\u001b[39;49mdriver, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    265\u001b[0m                    layer\u001b[39m=\u001b[39;49mlayer, enabled_drivers\u001b[39m=\u001b[39;49menabled_drivers, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    266\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    267\u001b[0m     \u001b[39mif\u001b[39;00m schema:\n\u001b[1;32m    268\u001b[0m         \u001b[39m# Make an ordered dict of schema properties.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fiona/collection.py:162\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    161\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m Session()\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mstart(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    163\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    164\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m WritingSession()\n",
      "File \u001b[0;32mfiona/ogrext.pyx:540\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_shim.pyx:90\u001b[0m, in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: dicra/analytics/sandbox/notebooks/SoilMoistureDeviance/Results/: No such file or directory"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "#Read geodataframe for mandal and district names to search in news articles\n",
    "gdf = gpd.read_file('dicra/analytics/sandbox/notebooks/SoilMoistureDeviance/Results/')\n",
    "mandal = list(gdf.Mandal_Nam.unique()) #unique mandals\n",
    "dist = list(gdf.Dist_Name.unique())    #unique districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
