{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a shapeName column containing the names of each Insurance Unit in lowercase and stripped\n",
    "insurance_names = pd.read_excel(r'C:\\Users\\mieke\\Documents\\Msc Thesis\\Notebooks Python\\Final\\insurance_names.xlsx', index_col = 0)\n",
    "insurance_names['shapeName'] = insurance_names['Insurance Unit'].copy()\n",
    "insurance_names.shapeName = insurance_names.shapeName.str.lower()\n",
    "insurance_names.shapeName = insurance_names.shapeName.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import files related to yields and insurance units\n",
    "yields = pd.read_excel(r'C:\\Users\\mieke\\Documents\\Msc Thesis\\Notebooks Python\\Final\\yields.xlsx', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Het valt op dat harapanahalli vanaf 2018 bij ballari behoort en daarvoor bij davanagere. Als ik naar de administrative boundaries kijk, dan behoort harapanahalli wel tot ballari en niet tot davanagere\n",
    "# Daarom veranderen we in de yield dataset voor alle datapunten waar Taluk = harapanahalli is gegeven, het district naar Ballari (eerst was dat Davanagere). Op internet lees je dat dit\n",
    "# Taluk deel is van Vijayanagara\n",
    "# Aangezien insurance_names gebasseerd is op yields, moeten we het ook daar aanpassen\n",
    "yields['District'] = np.where(yields['Taluk'] == 'harapanahalli', 'ballari', yields['District'])\n",
    "insurance_names['District'] = np.where(insurance_names['Taluk'] == 'harapanahalli', 'ballari', insurance_names['District'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_types = ['gp', 'h'] # Different bound types\n",
    "column_names = ['KGISGPName', 'KGISHobliN'] # Column names containing the name of the Insurance Unit\n",
    "path_types = ['C:/Users/mieke/Documents/Msc Thesis/Datasets/Shapefiles/Karnataka_gp_shp/', 'C:/Users/mieke/Documents/Msc Thesis/Datasets/Shapefiles/Karnataka_h_shp/'] # Different paths\n",
    "#non_indices = [[28, 23, 18, 4], [28, 26, 10]] # District names which do not occur in the yields dataframe (descending order is important) (eg 28:vijayanagara)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/mieke/Documents/Msc Thesis/Datasets/Shapefiles/Taluk/Taluk.shp'\n",
    "df_t = gpd.read_file(path)\n",
    "\n",
    "path = 'C:/Users/mieke/Documents/Msc Thesis/Datasets/Shapefiles/District_2016/District_2016.shp'\n",
    "df_d = gpd.read_file(path)\n",
    "df_d['KGISDist_1'] = df_d['KGISDist_1'].str.lower()\n",
    "df_district = df_d[['KGISDistri', 'KGISDist_1', 'geometry']]\n",
    "# Because the district vijayanagara exists since 2020 and was part of ballari in the past, we join these polygons and call the joined polygon ballari\n",
    "# We do this via QGIS: https://freegistutorial.com/how-to-export-layer-to-shapefile-on-qgis/, https://www.igismap.com/merge-two-polygons-points-polyline-shapefile/\n",
    "# We should also make sure that we set 31 (vijayanagara) to 12 (ballari) in the other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BOUNDARY DATA\n",
    "df_gp = pd.DataFrame() # create empty dataframe\n",
    "df_h = pd.DataFrame() # create empty dataframe\n",
    "\n",
    "# Loop over each of the bound types separately\n",
    "for t in range(len(bound_types)):\n",
    "    path = path_types[t] # Set path\n",
    "    folder_names = os.listdir(path) # contains all foldernames within the folder\n",
    "\n",
    "    district_names = [] # create list to include all unique district names within the bounds geodatframe\n",
    "\n",
    "    # This for loop creates one big geodataframe out of all separate district wise geodataframes\n",
    "    for i in folder_names:\n",
    "        input_shp = gpd.read_file(path + i + '/' + i + '.shp')\n",
    "        district_name = i[3:].lower() # district name as used within the bounds geodataframe\n",
    "        district_names.append(district_name)\n",
    "        input_shp['District'] = district_name\n",
    "        input_shp['KGISDistri'] = i[:2]\n",
    "        if t == 0:\n",
    "            df_gp = pd.concat([df_gp, input_shp], ignore_index=True)\n",
    "        elif t == 1:\n",
    "            df_h = pd.concat([df_h, input_shp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Vijayanagara to ballari and, hence, 31 to 12. We merged them and called it ballari\n",
    "df_h['District'] = np.where(df_h['District'] == 'vijayanagara', 'ballari', df_h['District'])\n",
    "df_h['KGISDistri'] = np.where(df_h['KGISDistri'] == '31', '12', df_h['KGISDistri'])\n",
    "df_t['KGISDistri'] = np.where(df_t['KGISDistri'] == '31', '12', df_t['KGISDistri'])\n",
    "df_gp['KGISDistri'] = np.where(df_gp['KGISDistri'] == '31', '12', df_gp['KGISDistri'])\n",
    "df_gp['District'] = np.where(df_gp['District'] == 'vijayanagara', 'ballari', df_gp['District'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe which combines all taluks with its corresponding district\n",
    "taluk_district = df_t.merge(df_district, how = 'left', on = 'KGISDistri')\n",
    "taluk_district = taluk_district[['KGISTalukC', 'KGISTalukN', 'KGISDistri', 'KGISDist_1', 'geometry_x']]\n",
    "taluk_district['KGISTalukN'] = taluk_district['KGISTalukN'].str.lower().drop_duplicates()\n",
    "taluk_district = taluk_district.sort_values(['KGISTalukN', 'KGISDist_1'], ascending = [True, True], ignore_index=True)\n",
    "taluk_district = taluk_district.rename(columns = {'KGISDist_1': 'District', 'geometry_x': 'geometry'})\n",
    "taluk_names = taluk_district['KGISTalukN'] # List of all taluk names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zetten nu in df_grampan, df_hobli, insurance_names en taluk_district dezelfde namen voor de districts en passen alles aan, zodat vijayanagara onder ballari valt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# Create shapeName column containing the Hobli/Gram Panchayat name in lower case\n",
    "# Create a geodataframe for Hobli/Gram Panchayat with solely the columns of interest\n",
    "\n",
    "df_hobli = df_h[['KGISHobliN', 'KGISTalukC', 'District', 'SHAPE_STAr', 'geometry']]\n",
    "df_hobli['shapeName'] = df_hobli['KGISHobliN'].str.lower()\n",
    "\n",
    "df_grampan = df_gp[['KGISGPName', 'KGISDistri', 'District', 'SHAPE_STAr', 'geometry']]\n",
    "df_grampan['shapeName'] = df_grampan['KGISGPName'].str.lower()\n",
    "df_grampan = df_grampan[~df_grampan['shapeName'].isna()] # drop NaN shapeNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "## We would like to set all district names equal to the names used within the taluk_district gdf (containing administrative district names)\n",
    "district_names = taluk_district['District'].unique() # list of all unique district names within the yields dataframe\n",
    "district_names = sorted(district_names) # sort the district names in ascending order\n",
    "\n",
    "## For insurance_names\n",
    "unique_districts = insurance_names['District'].unique() # list of all unique district names within the yields dataframe\n",
    "unique_districts = sorted(unique_districts) # sort the district names in ascending order\n",
    "\n",
    "# Make sure that the district names within the yields dataframe are equal to the spelling of the district names within the bounds geodataframe\n",
    "for i in range(len(unique_districts)):\n",
    "    insurance_names['District'] = np.where(insurance_names['District'] == unique_districts[i], district_names[i], insurance_names['District'])\n",
    "\n",
    "## For yields\n",
    "unique_districts = yields['District'].unique() # list of all unique district names within the yields dataframe\n",
    "unique_districts = sorted(unique_districts) # sort the district names in ascending order\n",
    "\n",
    "# Make sure that the district names within the yields dataframe are equal to the spelling of the district names within the bounds geodataframe\n",
    "for i in range(len(unique_districts)):\n",
    "    yields['District'] = np.where(yields['District'] == unique_districts[i], district_names[i], yields['District'])\n",
    "\n",
    "## For df_hobli\n",
    "unique_districts = df_hobli['District'].unique() # list of all unique district names within the yields dataframe\n",
    "unique_districts = sorted(unique_districts) # sort the district names in ascending order\n",
    "\n",
    "# Make sure that the district names within the yields dataframe are equal to the spelling of the district names within the bounds geodataframe\n",
    "for i in range(len(unique_districts)):\n",
    "    df_hobli['District'] = np.where(df_hobli['District'] == unique_districts[i], district_names[i], df_hobli['District'])\n",
    "\n",
    "\n",
    "## For df_grampan\n",
    "unique_districts = df_grampan['District'].unique() # list of all unique district names within the yields dataframe\n",
    "unique_districts = sorted(unique_districts) # sort the district names in ascending order\n",
    "\n",
    "# Make sure that the district names within the yields dataframe are equal to the spelling of the district names within the bounds geodataframe\n",
    "for i in range(len(unique_districts)):\n",
    "    df_grampan['District'] = np.where(df_grampan['District'] == unique_districts[i], district_names[i], df_grampan['District'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell checks whether each taluk intersects the corresponding district\n",
    "# Note: we also used contains instead of intersects, but this did not give the desired result\n",
    "num_intersects = []\n",
    "for i in taluk_district.index:\n",
    "    polya = np.array(df_district[df_district['KGISDist_1'] == taluk_district.loc[i, 'District']]['geometry'])[0] # District polygon\n",
    "    polyb = np.array(taluk_district[taluk_district['KGISTalukN'] == taluk_district.loc[i, 'KGISTalukN']]['geometry'])[0] # Taluk polygon\n",
    "    num_intersects.append(polya.intersects(polyb))\n",
    "sum(num_intersects) # Counts the number of True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hebben nu de taluk dataset samengevoegd met de district names van 2016. Nu willen we ook dat in beide bestanden dezelfde namen voor de taluks wordt gebruikt. Hiervoor kijken we dus naar insurance_names en taluk_district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We now check whether the same Taluk names are used within the yield and boundary files\n",
    "taluk_yield = insurance_names[['Taluk', 'District']].sort_values(['Taluk', 'District'], ignore_index=True).drop_duplicates()\n",
    "taluk_admin = taluk_district[['KGISTalukN', 'District']].sort_values(['KGISTalukN', 'District'], ignore_index=True).drop_duplicates()\n",
    "\n",
    "taluk_yield['Taluk_name'] = np.nan\n",
    "taluk_yield['Similarity'] = np.nan\n",
    "\n",
    "for i in taluk_yield.index:\n",
    "    indices = []\n",
    "    df_temp = taluk_admin[taluk_admin['District'] == taluk_yield['District'].loc[i]]\n",
    "    for j in df_temp.index:\n",
    "       indices.append(fuzz.token_set_ratio(taluk_yield.loc[i, 'Taluk'],df_temp.loc[j, 'KGISTalukN'])) # in this case, better than sort_ratio\n",
    "    taluk_yield.loc[i,'Taluk_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISTalukN'] # the shapeName corresponding to the highest similarity bound\n",
    "    taluk_yield.loc[i,'District_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'District'] # the shapeName corresponding to the highest similarity bound\n",
    "    taluk_yield.loc[i,'Similarity'] = np.max(indices) # the highest similarity found for the current insurance name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insurance Unit</th>\n",
       "      <th>Gram Panchayat/Hobli</th>\n",
       "      <th>District</th>\n",
       "      <th>Taluk</th>\n",
       "      <th>shapeName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>agrahara</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>agrahara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>anthapura</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>anthapura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>bandri</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>bandri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>bhujanganagara</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>bhujanganagara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>bommagatta</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>bommagatta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>choranuru</td>\n",
       "      <td>h</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>choranuru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>choranuru</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>choranuru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>devagiri</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>devagiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>gollalingamanahalli</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>gollalingamanahalli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>h.k.halli</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>h.k.halli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>kalingere</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>kalingere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>krishnanagara</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>krishnanagara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>metriki</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>metriki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>narasingapura</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>narasingapura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>nidugurthi</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>nidugurthi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>sandoor</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>sandoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>sanduru</td>\n",
       "      <td>h</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>sanduru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>shuseelanagara</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>shuseelanagara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>sovenahalli</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>sovenahalli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>tharanagara</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>tharanagara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223</th>\n",
       "      <td>toranagallu</td>\n",
       "      <td>h</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>toranagallu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5359</th>\n",
       "      <td>vaddu</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>vaddu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>vittalapura</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>vittalapura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5522</th>\n",
       "      <td>yashwanthnagara</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>sandur</td>\n",
       "      <td>yashwanthnagara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Insurance Unit Gram Panchayat/Hobli District   Taluk  \\\n",
       "58               agrahara                   gp  ballari  sandur   \n",
       "254             anthapura                   gp  ballari  sandur   \n",
       "544                bandri                   gp  ballari  sandur   \n",
       "824        bhujanganagara                   gp  ballari  sandur   \n",
       "911            bommagatta                   gp  ballari  sandur   \n",
       "1160            choranuru                    h  ballari  sandur   \n",
       "1161            choranuru                   gp  ballari  sandur   \n",
       "1239             devagiri                   gp  ballari  sandur   \n",
       "1517  gollalingamanahalli                   gp  ballari  sandur   \n",
       "1665            h.k.halli                   gp  ballari  sandur   \n",
       "2666            kalingere                   gp  ballari  sandur   \n",
       "3298        krishnanagara                   gp  ballari  sandur   \n",
       "3899              metriki                   gp  ballari  sandur   \n",
       "4203        narasingapura                   gp  ballari  sandur   \n",
       "4306           nidugurthi                   gp  ballari  sandur   \n",
       "4641              sandoor                   gp  ballari  sandur   \n",
       "4642              sanduru                    h  ballari  sandur   \n",
       "4867       shuseelanagara                   gp  ballari  sandur   \n",
       "4963          sovenahalli                   gp  ballari  sandur   \n",
       "5155          tharanagara                   gp  ballari  sandur   \n",
       "5223          toranagallu                    h  ballari  sandur   \n",
       "5359                vaddu                   gp  ballari  sandur   \n",
       "5427          vittalapura                   gp  ballari  sandur   \n",
       "5522      yashwanthnagara                   gp  ballari  sandur   \n",
       "\n",
       "                shapeName  \n",
       "58               agrahara  \n",
       "254             anthapura  \n",
       "544                bandri  \n",
       "824        bhujanganagara  \n",
       "911            bommagatta  \n",
       "1160            choranuru  \n",
       "1161            choranuru  \n",
       "1239             devagiri  \n",
       "1517  gollalingamanahalli  \n",
       "1665            h.k.halli  \n",
       "2666            kalingere  \n",
       "3298        krishnanagara  \n",
       "3899              metriki  \n",
       "4203        narasingapura  \n",
       "4306           nidugurthi  \n",
       "4641              sandoor  \n",
       "4642              sanduru  \n",
       "4867       shuseelanagara  \n",
       "4963          sovenahalli  \n",
       "5155          tharanagara  \n",
       "5223          toranagallu  \n",
       "5359                vaddu  \n",
       "5427          vittalapura  \n",
       "5522      yashwanthnagara  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This cell checks the datapoints for which the taluk names from the yield data are not exactly equal to the matched taluk names within the administrative boundary files  \n",
    "to_check = taluk_yield[taluk_yield['Taluk'] != taluk_yield['Taluk_name']]\n",
    "\n",
    "## The taluks are maybe not correctly matched are: hanur (64), hubballi (80), kalaburgi (95), kalaburgi north (96), sandur (156) \n",
    "# We use the following website to check which match is correct/most plausible\n",
    "# https://karnataka.gov.in/district/en\n",
    "# Besides, we also checked taluk_names to see whether a taluk name within another district is very much alike the taluk name of interest\n",
    "\n",
    "# hanur (64/1897):\n",
    "taluk_district[taluk_district['District'] == 'chamarajanagara']\n",
    "insurance_names[insurance_names['Taluk'] == 'hanur']\n",
    "# The match does not need to change: hanur == kollegala(hanur) 100% sure\n",
    "\n",
    "# # hubballi (80/2398) (nagara means city)\n",
    "taluk_district[taluk_district['District'] == 'dharwad']\n",
    "insurance_names[insurance_names['Taluk'] == 'hubballi']\n",
    "# # The match needs to change: hubballi == hubli 100% sure\n",
    "# https://en.wikipedia.org/wiki/Hubli_Taluk\n",
    "taluk_yield.loc[2398, 'Taluk_name'] = 'hubli'\n",
    "\n",
    "# # kalaburgi (95/2878)\n",
    "taluk_district[taluk_district['District'] == 'kalburgi']\n",
    "insurance_names[insurance_names['Taluk'] == 'kalaburgi']\n",
    "# # The match needs to change: kalaburgi == gulbarga 100% sure\n",
    "# https://vlist.in/sub-district/05582.html\n",
    "taluk_yield.loc[2878, 'Taluk_name'] = 'gulbarga'\n",
    "\n",
    "# # kalaburgi north (96/2919)\n",
    "taluk_district[taluk_district['District'] == 'kalburgi']\n",
    "insurance_names[insurance_names['Taluk'] == 'kalaburgi north']\n",
    "# # The match needs to change: kalaburgi north == kamalapura 100% sure\n",
    "taluk_yield.loc[2919, 'Taluk_name'] = 'kamalapura'\n",
    "\n",
    "# # sandur (156/4487)\n",
    "taluk_district[taluk_district['District'] == 'ballari']\n",
    "insurance_names[insurance_names['Taluk'] == 'sandur']\n",
    "# # The match does not need to change: sandur == sonduru 100% sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "194\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Taluk</th>\n",
       "      <th>District</th>\n",
       "      <th>Taluk_name</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>District_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>kalaburgi north</td>\n",
       "      <td>kalburgi</td>\n",
       "      <td>kamalapura</td>\n",
       "      <td>57.0</td>\n",
       "      <td>kalburgi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>kamalapura</td>\n",
       "      <td>kalburgi</td>\n",
       "      <td>kamalapura</td>\n",
       "      <td>100.0</td>\n",
       "      <td>kalburgi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Taluk  District  Taluk_name  Similarity District_name\n",
       "2919  kalaburgi north  kalburgi  kamalapura        57.0      kalburgi\n",
       "2954       kamalapura  kalburgi  kamalapura       100.0      kalburgi"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now, also check whether each polygon is used for just one taluk\n",
    "print(np.size(taluk_yield,0))\n",
    "print(np.size(taluk_yield[['Taluk_name', 'District']].drop_duplicates(),0))\n",
    "taluk_yield[taluk_yield[['Taluk_name', 'District']].duplicated(keep=False)]\n",
    "# This shows that we use one taluk name more than once: kamalapura. This Taluk name is used for kalaburgi north and kamalapura. \n",
    "# However, after studying the yield dataset, this seems as a valid choice \n",
    "\n",
    "#yields[(yields['Taluk'] == 'kamalapura')]\n",
    "#yields[(yields['Taluk'] == 'kalaburgi north')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hence, we now know which taluk name within the administrative boundary files corresponds to the taluk name within the yield data. \n",
    "# For ease, we replace the taluk names within the yield file with the taluk names within the administrative boundary files.\n",
    "for i in taluk_yield.index:\n",
    "    yields['Taluk'] = np.where(yields['Taluk'] == taluk_yield.loc[i, 'Taluk'], taluk_yield.loc[i, 'Taluk_name'], yields['Taluk'])\n",
    "    insurance_names['Taluk'] = np.where(insurance_names['Taluk'] == taluk_yield.loc[i, 'Taluk'], taluk_yield.loc[i, 'Taluk_name'], insurance_names['Taluk'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hebben nu de taluk dataset samengevoegd met de district names van 2016. Nu willen we de hobli's en gram panchayat's koppelen aan de taluks. We beginnen hierbij met de hobli's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that for the hobli level the corresponding taluk names are given\n",
    "df_hobli_taluk = df_hobli.merge(taluk_district, how = 'left', on = ['KGISTalukC'])\n",
    "df_hobli_taluk = df_hobli_taluk[['KGISHobliN', 'shapeName', 'KGISTalukC', 'KGISTalukN', 'KGISDistri', 'District_x', 'SHAPE_STAr', 'geometry_x']]\n",
    "df_hobli_taluk = df_hobli_taluk.rename(columns = {'District_x': 'District', 'geometry_x': 'geometry'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg:32643\n",
      "epsg:32643\n",
      "epsg:32643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\pyproj\\crs\\crs.py:130: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    }
   ],
   "source": [
    "print(df_t.crs) # epsg:32643\n",
    "print(df_h.crs) # epsg:32643\n",
    "print(df_gp.crs) # epsg:32643\n",
    "\n",
    "# Transform the geometry and yields_geometry dataframes to geodataframes\n",
    "# Then, save the geometry and yields_geometry geodataframes\n",
    "taluk_district = gpd.GeoDataFrame(taluk_district, geometry = taluk_district.geometry, crs = {'init': 'epsg:32643'}) # 32643 is the original crs (found by using .crs for one of the input shp files)\n",
    "#taluk_district.geometry = taluk_district.geometry.to_crs(epsg = 4326) # Set crs to 4326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HIER ZIJN WE GESTOPT MET OPNIEUW RUNNEN VOOR 'SHAPE_STAr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpd_join_temp = gpd.sjoin(df_grampan, taluk_district, how='left', predicate='intersects') # 12189\n",
    "# gpd_join_temp1 = gpd_join_temp[gpd_join_temp['District_left'] == gpd_join_temp['District_right']].reset_index() # 10255\n",
    "# gpd_join_temp1['area'] = np.nan\n",
    "# gpd_join_temp1 = gpd_join_temp1\n",
    "# for i in gpd_join_temp1.index:\n",
    "#     p = np.array(gpd_join_temp1[(gpd_join_temp1['geometry'] == gpd_join_temp1.loc[i, 'geometry'])]['geometry'])[0]\n",
    "#     q = np.array(taluk_district[(taluk_district['District'] == gpd_join_temp1.loc[i, 'District_left']) & (taluk_district['KGISTalukN'] == gpd_join_temp1.loc[i, 'KGISTalukN'])]['geometry'])[0]\n",
    "#     gpd_join_temp1.loc[i, 'area'] = p.intersection(q).area\n",
    "# gpd_join_temp1a = gpd_join_temp1.sort_values(['index', 'area'], ascending = [True, False]) # sort values\n",
    "# gpd_join_temp2 = gpd_join_temp1a.drop_duplicates(subset = 'index', keep = 'first') # only keep the combination for which the intersected area is largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpd_join_temp1.to_file(r'C:\\Users\\mieke\\Documents\\Msc Thesis\\Notebooks Python\\gpd_join_temp1.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL IF YOU WOULD NOT LIKE TO RECREATE THIS EXTENSIVE DATAFRAME AGAIN\n",
    "gpd_join_temp1 = gpd.read_file(r'C:\\Users\\mieke\\Documents\\Msc Thesis\\Notebooks Python\\Final\\gpd_join_temp1.geojson')\n",
    "gpd_join_temp1a = gpd_join_temp1.sort_values(['index', 'area'], ascending = [True, False]) # sort values\n",
    "gpd_join_temp2 = gpd_join_temp1a.drop_duplicates(subset = 'index', keep = 'first') # only keep the combination for which the intersected area is largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select the columns of interest from the derived geodataframe\n",
    "df_grampan_taluk = gpd_join_temp2[['KGISGPName', 'shapeName', 'KGISTalukC', 'KGISTalukN', 'KGISDistri_left', 'District_left', 'SHAPE_STAr', 'geometry']]\n",
    "df_grampan_taluk = df_grampan_taluk.rename(columns = {'KGISDistri_left': 'KGISDistri', 'District_left': 'District'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we drop all duplicates for which we have multiple polygons with equal Insurance Unit name, taluk name and district name. We keep the polygon with the largest area.\n",
    "df_hobli_taluk = df_hobli_taluk.sort_values(['shapeName', 'KGISTalukN', 'District', 'SHAPE_STAr'], ascending = [True, True, True, False], ignore_index = True)\n",
    "df_hobli_taluk_sel = df_hobli_taluk.drop_duplicates(subset = ['shapeName', 'KGISTalukN', 'District'], keep = 'first', ignore_index = True)\n",
    "\n",
    "df_grampan_taluk = df_grampan_taluk.sort_values(['shapeName', 'KGISTalukN', 'District', 'SHAPE_STAr'], ascending = [True, True, True, False], ignore_index = True)\n",
    "df_grampan_taluk_sel = df_grampan_taluk.drop_duplicates(subset = ['shapeName', 'KGISTalukN', 'District'], keep = 'first', ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misschien kunnen we beter eerst de insurance_names matchen met de gp's en hoblis. Voor hobli's kunnen we dit doen op district+taluk niveau. Voor gp's kunnen we dit doen op district niveau\n",
    "hobli = insurance_names[insurance_names['Gram Panchayat/Hobli'] == 'h'].sort_values(['shapeName', 'Taluk', 'District'], ignore_index=True).drop_duplicates(ignore_index=True)\n",
    "grampan = insurance_names[insurance_names['Gram Panchayat/Hobli'] == 'gp'].sort_values(['shapeName', 'Taluk', 'District'], ignore_index=True).drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hobli['Insurance_name'] = np.nan\n",
    "hobli['shape_name'] = np.nan\n",
    "hobli['Taluk_name'] = np.nan\n",
    "hobli['District_name'] = np.nan\n",
    "hobli['Similarity'] = np.nan\n",
    "hobli['geometry'] = np.nan\n",
    "\n",
    "for i in hobli.index:\n",
    "    indices = []\n",
    "    df_temp = df_hobli_taluk_sel[(df_hobli_taluk_sel['District'] == hobli['District'].loc[i]) & (df_hobli_taluk_sel['KGISTalukN'] == hobli['Taluk'].loc[i])]\n",
    "    for j in df_temp.index:\n",
    "       indices.append(fuzz.token_set_ratio(hobli.loc[i, 'shapeName'],df_temp.loc[j, 'shapeName'])) # in this case, better than sort_ratio\n",
    "    hobli.loc[i,'shape_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'shapeName'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Insurance_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISHobliN'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Taluk_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISTalukN'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'District_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'District'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Similarity'] = np.max(indices) # the highest similarity found for the current insurance name\n",
    "    hobli.loc[i,'geometry'] = df_temp.loc[df_temp.index[np.argmax(indices)],'geometry'] # the shapeName corresponding to the highest similarity bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grampan['Insurance_name'] = np.nan\n",
    "grampan['shape_name'] = np.nan\n",
    "grampan['Taluk_name'] = np.nan\n",
    "grampan['District_name'] = np.nan\n",
    "grampan['Similarity'] = np.nan\n",
    "grampan['geometry'] = np.nan\n",
    "\n",
    "for i in grampan.index:\n",
    "    indices = []\n",
    "    df_temp = df_grampan_taluk_sel[(df_grampan_taluk_sel['District'] == grampan['District'].loc[i]) & (df_grampan_taluk_sel['KGISTalukN'] == grampan['Taluk'].loc[i])]\n",
    "    for j in df_temp.index:\n",
    "       indices.append(fuzz.token_set_ratio(grampan.loc[i, 'shapeName'],df_temp.loc[j, 'shapeName'])) # in this case, better than sort_ratio\n",
    "    grampan.loc[i,'shape_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'shapeName'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Insurance_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISGPName'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Taluk_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISTalukN'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'District_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'District'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Similarity'] = np.max(indices) # the highest similarity found for the current insurance name\n",
    "    grampan.loc[i,'geometry'] = df_temp.loc[df_temp.index[np.argmax(indices)],'geometry'] # the shapeName corresponding to the highest similarity bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_hobli = hobli[hobli['shapeName'] != hobli['shape_name']] # We moeten er 47 handmatig toewijzen\n",
    "check_hobli_df = check_hobli[['shapeName', 'shape_name']]\n",
    "hobli_names = sorted(df_hobli_taluk_sel['shapeName'].unique())\n",
    "\n",
    "check_grampan = grampan[grampan['shapeName'] != grampan['shape_name']] # we moeten er handmatig 1757 toewijzen\n",
    "check_grampan_df = check_grampan[['shapeName', 'shape_name']]\n",
    "grampan_names = sorted(df_grampan_taluk_sel['shapeName'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mieke\\AppData\\Local\\Temp\\ipykernel_25160\\2004751769.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_hobli_taluk_sel['shapeName'] = np.where(df_hobli_taluk_sel['shapeName'] == 'bidadi 1', 'bidadi', df_hobli_taluk_sel['shapeName'])\n",
      "C:\\Users\\mieke\\AppData\\Local\\Temp\\ipykernel_25160\\2004751769.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_hobli_taluk_sel['shapeName'] = np.where(df_hobli_taluk_sel['shapeName'] == 'kailancha-1', 'kailancha', df_hobli_taluk_sel['shapeName'])\n"
     ]
    }
   ],
   "source": [
    "for i in check_hobli.index:\n",
    "    indices = []\n",
    "    df_temp = df_hobli_taluk_sel[(df_hobli_taluk_sel['District'] == hobli['District'].loc[i]) & (df_hobli_taluk_sel['KGISTalukN'] == hobli['Taluk'].loc[i])]\n",
    "    for j in df_temp.index:\n",
    "       indices.append(fuzz.token_sort_ratio(hobli.loc[i, 'shapeName'],df_temp.loc[j, 'shapeName'])) # in this case, better than sort_ratio\n",
    "    hobli.loc[i,'shape_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'shapeName'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Insurance_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISHobliN'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Taluk_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISTalukN'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'District_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'District'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Similarity'] = np.max(indices) # the highest similarity found for the current insurance name\n",
    "    hobli.loc[i,'geometry'] = df_temp.loc[df_temp.index[np.argmax(indices)],'geometry'] # the shapeName corresponding to the highest similarity bound\n",
    "\n",
    "check_hobli2 = hobli[hobli['shapeName'] != hobli['shape_name']] # We moeten er 5 handmatig toewijzen\n",
    "check_hobli_df2 = check_hobli2[['shapeName', 'shape_name']]\n",
    "\n",
    "for i in check_hobli2.index:\n",
    "    indices = []\n",
    "    df_temp = df_hobli_taluk_sel[(df_hobli_taluk_sel['District'] == hobli['District'].loc[i])]\n",
    "    for j in df_temp.index:\n",
    "       indices.append(fuzz.token_set_ratio(hobli.loc[i, 'shapeName'],df_temp.loc[j, 'shapeName'])) # in this case, better than sort_ratio\n",
    "    hobli.loc[i,'shape_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'shapeName'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Insurance_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISHobliN'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Taluk_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISTalukN'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'District_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'District'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Similarity'] = np.max(indices) # the highest similarity found for the current insurance name\n",
    "    hobli.loc[i,'geometry'] = df_temp.loc[df_temp.index[np.argmax(indices)],'geometry'] # the shapeName corresponding to the highest similarity bound\n",
    "\n",
    "check_hobli3 = hobli[hobli['shapeName'] != hobli['shape_name']] # We moeten er 5 handmatig toewijzen\n",
    "check_hobli_df3 = check_hobli3[['shapeName', 'shape_name']]\n",
    "\n",
    "for i in check_hobli3.index:\n",
    "    indices = []\n",
    "    df_temp = df_hobli_taluk_sel[(df_hobli_taluk_sel['District'] == hobli['District'].loc[i])]\n",
    "    for j in df_temp.index:\n",
    "       indices.append(fuzz.token_sort_ratio(hobli.loc[i, 'shapeName'],df_temp.loc[j, 'shapeName'])) # in this case, better than sort_ratio\n",
    "    hobli.loc[i,'shape_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'shapeName'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Insurance_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISHobliN'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Taluk_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISTalukN'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'District_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'District'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Similarity'] = np.max(indices) # the highest similarity found for the current insurance name\n",
    "    hobli.loc[i,'geometry'] = df_temp.loc[df_temp.index[np.argmax(indices)],'geometry'] # the shapeName corresponding to the highest similarity bound\n",
    "\n",
    "check_hobli4 = hobli[hobli['shapeName'] != hobli['shape_name']] # We moeten er 5 handmatig toewijzen\n",
    "check_hobli_df4 = check_hobli4[['shapeName', 'shape_name']]\n",
    "\n",
    "# There are just 2 hoblis left which should be matched manually: bidadi and kailancha\n",
    "# The boundary data has options: bidadi 1 and bidadi 2, kailancha-1 and kailancha-2\n",
    "# These options do not already occur in the hobli names within the yield data\n",
    "hobli_yield = hobli['shapeName'].unique()\n",
    "# Hence, we select the ones with the number 1 (also because they are slightly bigger)\n",
    "# df_hobli_taluk_sel[df_hobli_taluk_sel['shapeName'] == 'kailancha-1']\n",
    "\n",
    "# We do this by changing the boundary name within the geodataframe\n",
    "df_hobli_taluk_sel['shapeName'] = np.where(df_hobli_taluk_sel['shapeName'] == 'bidadi 1', 'bidadi', df_hobli_taluk_sel['shapeName'])\n",
    "df_hobli_taluk_sel['shapeName'] = np.where(df_hobli_taluk_sel['shapeName'] == 'kailancha-1', 'kailancha', df_hobli_taluk_sel['shapeName'])\n",
    "\n",
    "for i in check_hobli4.index:\n",
    "    indices = []\n",
    "    df_temp = df_hobli_taluk_sel[(df_hobli_taluk_sel['District'] == hobli['District'].loc[i])]\n",
    "    for j in df_temp.index:\n",
    "       indices.append(fuzz.token_sort_ratio(hobli.loc[i, 'shapeName'],df_temp.loc[j, 'shapeName'])) # in this case, better than sort_ratio\n",
    "    hobli.loc[i,'shape_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'shapeName'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Insurance_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISHobliN'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Taluk_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISTalukN'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'District_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'District'] # the shapeName corresponding to the highest similarity bound\n",
    "    hobli.loc[i,'Similarity'] = np.max(indices) # the highest similarity found for the current insurance name\n",
    "    hobli.loc[i,'geometry'] = df_temp.loc[df_temp.index[np.argmax(indices)],'geometry'] # the shapeName corresponding to the highest similarity bound\n",
    "\n",
    "check_hobli5 = hobli[hobli['shapeName'] != hobli['shape_name']] \n",
    "check_hobli_df5 = check_hobli5[['shapeName', 'shape_name']] # empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in check_grampan.index:\n",
    "    indices = []\n",
    "    df_temp = df_grampan_taluk_sel[(df_grampan_taluk_sel['District'] == grampan['District'].loc[i]) & (df_grampan_taluk_sel['KGISTalukN'] == grampan['Taluk'].loc[i])]\n",
    "    for j in df_temp.index:\n",
    "       indices.append(fuzz.token_sort_ratio(grampan.loc[i, 'shapeName'],df_temp.loc[j, 'shapeName'])) # in this case, better than sort_ratio\n",
    "    grampan.loc[i,'shape_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'shapeName'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Insurance_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISGPName'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Taluk_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISTalukN'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'District_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'District'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Similarity'] = np.max(indices) # the highest similarity found for the current insurance name\n",
    "    grampan.loc[i,'geometry'] = df_temp.loc[df_temp.index[np.argmax(indices)],'geometry'] # the shapeName corresponding to the highest similarity bound\n",
    "\n",
    "check_grampan2 = grampan[grampan['shapeName'] != grampan['shape_name']] # We moeten er 5 handmatig toewijzen\n",
    "check_grampan_df2 = check_grampan2[['shapeName', 'shape_name']]\n",
    "\n",
    "for i in check_grampan2.index:\n",
    "    indices = []\n",
    "    df_temp = df_grampan_taluk_sel[(df_grampan_taluk_sel['District'] == grampan['District'].loc[i])]\n",
    "    for j in df_temp.index:\n",
    "       indices.append(fuzz.token_set_ratio(grampan.loc[i, 'shapeName'],df_temp.loc[j, 'shapeName'])) # in this case, better than sort_ratio\n",
    "    grampan.loc[i,'shape_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'shapeName'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Insurance_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISGPName'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Taluk_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISTalukN'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'District_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'District'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Similarity'] = np.max(indices) # the highest similarity found for the current insurance name\n",
    "    grampan.loc[i,'geometry'] = df_temp.loc[df_temp.index[np.argmax(indices)],'geometry'] # the shapeName corresponding to the highest similarity bound\n",
    "\n",
    "check_grampan3 = grampan[grampan['shapeName'] != grampan['shape_name']] # We moeten er 5 handmatig toewijzen\n",
    "check_grampan_df3 = check_grampan3[['shapeName', 'shape_name']]\n",
    "\n",
    "for i in check_grampan3.index:\n",
    "    indices = []\n",
    "    df_temp = df_grampan_taluk_sel[(df_grampan_taluk_sel['District'] == grampan['District'].loc[i])]\n",
    "    for j in df_temp.index:\n",
    "       indices.append(fuzz.token_sort_ratio(grampan.loc[i, 'shapeName'],df_temp.loc[j, 'shapeName'])) # in this case, better than sort_ratio\n",
    "    grampan.loc[i,'shape_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'shapeName'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Insurance_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISGPName'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Taluk_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISTalukN'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'District_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'District'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Similarity'] = np.max(indices) # the highest similarity found for the current insurance name\n",
    "    grampan.loc[i,'geometry'] = df_temp.loc[df_temp.index[np.argmax(indices)],'geometry'] # the shapeName corresponding to the highest similarity bound\n",
    "\n",
    "check_grampan4 = grampan[grampan['shapeName'] != grampan['shape_name']] # We moeten er 5 handmatig toewijzen\n",
    "check_grampan_df4 = check_grampan4[['shapeName', 'shape_name']]\n",
    "\n",
    "# There are just 2 hoblis left which should be matched manually: bidadi and kailancha\n",
    "# The boundary data has options: bidadi 1 and bidadi 2, kailancha-1 and kailancha-2\n",
    "# These options do not already occur in the hobli names within the yield data\n",
    "grampan_yield = grampan['shapeName'].unique()\n",
    "# Hence, we select the ones with the number 1 (also because they are slightly bigger)\n",
    "# df_hobli_taluk_sel[df_hobli_taluk_sel['shapeName'] == 'kailancha-1']\n",
    "\n",
    "# We do this by changing the boundary name within the geodataframe\n",
    "# df_grampan_taluk_sel['shapeName'] = np.where(df_grampan_taluk_sel['shapeName'] == 'bidadi 1', 'bidadi', df_grampan_taluk_sel['shapeName'])\n",
    "# df_grampan_taluk_sel['shapeName'] = np.where(df_grampan_taluk_sel['shapeName'] == 'kailancha-1', 'kailancha', df_grampan_taluk_sel['shapeName'])\n",
    "\n",
    "# for i in check_grampan4.index:\n",
    "#     indices = []\n",
    "#     df_temp = df_grampan_taluk_sel[(df_grampan_taluk_sel['District'] == grampan['District'].loc[i])]\n",
    "#     for j in df_temp.index:\n",
    "#        indices.append(fuzz.token_sort_ratio(grampan.loc[i, 'shapeName'],df_temp.loc[j, 'shapeName'])) # in this case, better than sort_ratio\n",
    "#     grampan.loc[i,'shape_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'shapeName'] # the shapeName corresponding to the highest similarity bound\n",
    "#     grampan.loc[i,'Insurance_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISGPName'] # the shapeName corresponding to the highest similarity bound\n",
    "#     grampan.loc[i,'Taluk_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISTalukN'] # the shapeName corresponding to the highest similarity bound\n",
    "#     grampan.loc[i,'District_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'District'] # the shapeName corresponding to the highest similarity bound\n",
    "#     grampan.loc[i,'Similarity'] = np.max(indices) # the highest similarity found for the current insurance name\n",
    "#     grampan.loc[i,'geometry'] = df_temp.loc[df_temp.index[np.argmax(indices)],'geometry'] # the shapeName corresponding to the highest similarity bound\n",
    "\n",
    "# check_grampan5 = grampan[grampan['shapeName'] != grampan['shape_name']] \n",
    "# check_grampan_df5 = check_grampan5[['shapeName', 'shape_name']] # empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in check_grampan4.index:\n",
    "    indices = []\n",
    "    df_temp = df_grampan_taluk_sel.copy()#[(df_grampan_taluk_sel['District'] == grampan['District'].loc[i])]\n",
    "    for j in df_temp.index:\n",
    "       indices.append(fuzz.token_set_ratio(grampan.loc[i, 'shapeName'],df_temp.loc[j, 'shapeName'])) # in this case, better than sort_ratio\n",
    "    grampan.loc[i,'shape_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'shapeName'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Insurance_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISGPName'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Taluk_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISTalukN'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'District_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'District'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Similarity'] = np.max(indices) # the highest similarity found for the current insurance name\n",
    "    grampan.loc[i,'geometry'] = df_temp.loc[df_temp.index[np.argmax(indices)],'geometry'] # the shapeName corresponding to the highest similarity bound\n",
    "\n",
    "check_grampan5 = grampan[grampan['shapeName'] != grampan['shape_name']] \n",
    "check_grampan_df5 = check_grampan5[['shapeName', 'shape_name']] # empty\n",
    "\n",
    "for i in check_grampan5.index:\n",
    "    indices = []\n",
    "    df_temp = df_grampan_taluk_sel.copy()#[(df_grampan_taluk_sel['District'] == grampan['District'].loc[i])]\n",
    "    for j in df_temp.index:\n",
    "       indices.append(fuzz.token_sort_ratio(grampan.loc[i, 'shapeName'],df_temp.loc[j, 'shapeName'])) # in this case, better than sort_ratio\n",
    "    grampan.loc[i,'shape_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'shapeName'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Insurance_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISGPName'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Taluk_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'KGISTalukN'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'District_name'] = df_temp.loc[df_temp.index[np.argmax(indices)],'District'] # the shapeName corresponding to the highest similarity bound\n",
    "    grampan.loc[i,'Similarity'] = np.max(indices) # the highest similarity found for the current insurance name\n",
    "    grampan.loc[i,'geometry'] = df_temp.loc[df_temp.index[np.argmax(indices)],'geometry'] # the shapeName corresponding to the highest similarity bound\n",
    "\n",
    "check_grampan6 = grampan[grampan['shapeName'] != grampan['shape_name']] \n",
    "check_grampan_df6 = check_grampan6[['shapeName', 'shape_name']] # empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528\n",
      "528\n",
      "4989\n",
      "4765\n",
      "224\n",
      "224\n"
     ]
    }
   ],
   "source": [
    "valid_grampan = grampan[grampan['shapeName'] == grampan['shape_name']]\n",
    "valid_hobli = hobli[hobli['shapeName'] == hobli['shape_name']]\n",
    "print(np.size(hobli,0))\n",
    "print(np.size(valid_hobli,0))\n",
    "print(np.size(grampan,0))\n",
    "print(np.size(valid_grampan,0))\n",
    "print(np.size(grampan,0) - np.size(valid_grampan,0))\n",
    "print(np.size(check_grampan_df6,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields['shapeName'] = yields['Insurance Unit'].copy()\n",
    "yields.shapeName = yields.shapeName.str.lower()\n",
    "yields.shapeName = yields.shapeName.str.strip()\n",
    "\n",
    "yields_hobli = yields[yields['Gram Panchayat/Hobli'] == 'h']\n",
    "yields_grampan = yields[yields['Gram Panchayat/Hobli'] == 'gp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19366\n",
      "18604\n",
      "762\n"
     ]
    }
   ],
   "source": [
    "merge_hobli = yields_hobli.merge(valid_hobli, how = 'left', on = ['shapeName', 'Gram Panchayat/Hobli', 'District', 'Taluk'])\n",
    "merge_grampan = yields_grampan.merge(valid_grampan, how = 'left', on = ['shapeName', 'Gram Panchayat/Hobli', 'District', 'Taluk'])\n",
    "print(np.size(merge_grampan,0))\n",
    "merge_grampan = merge_grampan[~merge_grampan['geometry'].isna()]\n",
    "print(np.size(merge_grampan,0))\n",
    "yields_geometries = pd.concat([merge_grampan, merge_hobli], ignore_index=True)\n",
    "print(19366-18604) # We have 762 observations for which we miss a geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22114\n",
      "21352\n",
      "762\n"
     ]
    }
   ],
   "source": [
    "print(np.size(yields,0))\n",
    "print(np.size(yields_geometries,0))\n",
    "print(np.size(yields,0) - np.size(yields_geometries,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg:32643\n",
      "epsg:32643\n",
      "epsg:32643\n",
      "+init=epsg:32643 +type=crs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\pyproj\\crs\\crs.py:130: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg:4326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Insurance Unit</th>\n",
       "      <th>shapeName</th>\n",
       "      <th>Gram Panchayat/Hobli</th>\n",
       "      <th>District</th>\n",
       "      <th>Taluk</th>\n",
       "      <th>Crop</th>\n",
       "      <th>IRR_RF</th>\n",
       "      <th>Average Yield(Kg/Ha)</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>114. danapura</td>\n",
       "      <td>114. danapura</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>hospet</td>\n",
       "      <td>paddy</td>\n",
       "      <td>irr</td>\n",
       "      <td>5545.67</td>\n",
       "      <td>POLYGON ((76.40937 15.19414, 76.40658 15.19403...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Season Insurance Unit      shapeName Gram Panchayat/Hobli District  \\\n",
       "0  2017  Kharif  114. danapura  114. danapura                   gp  ballari   \n",
       "\n",
       "    Taluk   Crop IRR_RF  Average Yield(Kg/Ha)  \\\n",
       "0  hospet  paddy    irr               5545.67   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((76.40937 15.19414, 76.40658 15.19403...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yields_geometries = yields_geometries[['Year', 'Season', 'Insurance Unit_x', 'shapeName', 'Gram Panchayat/Hobli', 'District', 'Taluk', 'Crop', 'IRR_RF', 'Average Yield(Kg/Ha)', 'geometry']]\n",
    "yields_geometries = yields_geometries.rename(columns = {'Insurance Unit_x': 'Insurance Unit'})\n",
    "\n",
    "print(df_t.crs) # epsg:32643\n",
    "print(df_h.crs) # epsg:32643\n",
    "print(df_gp.crs) # epsg:32643\n",
    "\n",
    "# Transform the geometry and yields_geometry dataframes to geodataframes\n",
    "# Then, save the geometry and yields_geometry geodataframes\n",
    "yields_geometries = gpd.GeoDataFrame(yields_geometries, geometry = yields_geometries.geometry, crs = {'init': 'epsg:32643'}) # 32643 is the original crs (found by using .crs for one of the input shp files)\n",
    "print(yields_geometries.crs) # epsg:32643\n",
    "yields_geometries.geometry = yields_geometries.geometry.to_crs(epsg = 4326) # Set crs to 4326\n",
    "print(yields_geometries.crs) # epsg:32643\n",
    "yields_geometries.to_file(r'C:\\Users\\mieke\\Documents\\Msc Thesis\\Notebooks Python\\Final\\yields_geometry.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "yields_geometries.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insurance Unit</th>\n",
       "      <th>shapeName</th>\n",
       "      <th>Gram Panchayat/Hobli</th>\n",
       "      <th>District</th>\n",
       "      <th>Taluk</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114. danapura</td>\n",
       "      <td>114. danapura</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>hospet</td>\n",
       "      <td>POLYGON ((76.40937 15.19414, 76.40658 15.19403...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Insurance Unit      shapeName Gram Panchayat/Hobli District   Taluk  \\\n",
       "0  114. danapura  114. danapura                   gp  ballari  hospet   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((76.40937 15.19414, 76.40658 15.19403...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_names = yields_geometries.sort_values(['Insurance Unit'], ascending=True, ignore_index=True)\n",
    "valid_names = valid_names.iloc[:,[2,3,4,5,6,10]]\n",
    "valid_names.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insurance Unit</th>\n",
       "      <th>shapeName</th>\n",
       "      <th>Gram Panchayat/Hobli</th>\n",
       "      <th>District</th>\n",
       "      <th>Taluk</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114. danapura</td>\n",
       "      <td>114. danapura</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>hospet</td>\n",
       "      <td>POLYGON ((76.40937 15.19414, 76.40658 15.19403...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Insurance Unit      shapeName Gram Panchayat/Hobli District   Taluk  \\\n",
       "0  114. danapura  114. danapura                   gp  ballari  hospet   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((76.40937 15.19414, 76.40658 15.19403...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_names = yields_geometries.sort_values(['shapeName'], ascending=True, ignore_index=True)\n",
    "valid_names = valid_names.iloc[:,[2,3,4,5,6,10]]\n",
    "valid_names = valid_names.drop_duplicates(subset = ['shapeName', 'Gram Panchayat/Hobli', 'District', 'Taluk'], ignore_index=True)\n",
    "valid_names.to_file(r'C:\\Users\\mieke\\Documents\\Msc Thesis\\Notebooks Python\\Final\\insurance_names.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "#valid_names.to_excel(r'C:\\Users\\mieke\\Documents\\Msc Thesis\\Notebooks Python\\Final\\insurance_names.xlsx', header=True, index=True)\n",
    "valid_names.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Insurance Unit</th>\n",
       "      <th>shapeName</th>\n",
       "      <th>Gram Panchayat/Hobli</th>\n",
       "      <th>District</th>\n",
       "      <th>Taluk</th>\n",
       "      <th>Crop</th>\n",
       "      <th>IRR_RF</th>\n",
       "      <th>Average Yield(Kg/Ha)</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>114. danapura</td>\n",
       "      <td>114. danapura</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>hospet</td>\n",
       "      <td>paddy</td>\n",
       "      <td>irr</td>\n",
       "      <td>5545.67</td>\n",
       "      <td>POLYGON ((76.40937 15.19414, 76.40658 15.19403...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Season Insurance Unit      shapeName Gram Panchayat/Hobli District  \\\n",
       "0  2017  Kharif  114. danapura  114. danapura                   gp  ballari   \n",
       "\n",
       "    Taluk   Crop IRR_RF  Average Yield(Kg/Ha)  \\\n",
       "0  hospet  paddy    irr               5545.67   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((76.40937 15.19414, 76.40658 15.19403...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_calculation = yields_geometries.sort_values(['shapeName'], ascending=True, ignore_index=True)\n",
    "#obs_calculation = obs_calculation.iloc[:,[0,1,2,3,4,5,6,10]]\n",
    "obs_calculation = obs_calculation.drop_duplicates(subset = ['Year', 'Season', 'shapeName', 'Gram Panchayat/Hobli', 'District', 'Taluk'], ignore_index=True)\n",
    "obs_calculation.to_file(r'C:\\Users\\mieke\\Documents\\Msc Thesis\\Notebooks Python\\Final\\obs_calculation.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "#valid_names.to_excel(r'C:\\Users\\mieke\\Documents\\Msc Thesis\\Notebooks Python\\Final\\insurance_names.xlsx', header=True, index=True)\n",
    "obs_calculation.head(1) # This dataframe contains each unique geometry for year, crop, season, unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Insurance Unit</th>\n",
       "      <th>shapeName</th>\n",
       "      <th>Gram Panchayat/Hobli</th>\n",
       "      <th>District</th>\n",
       "      <th>Taluk</th>\n",
       "      <th>Crop</th>\n",
       "      <th>IRR_RF</th>\n",
       "      <th>Average Yield(Kg/Ha)</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>114. danapura</td>\n",
       "      <td>114. danapura</td>\n",
       "      <td>gp</td>\n",
       "      <td>ballari</td>\n",
       "      <td>hospet</td>\n",
       "      <td>paddy</td>\n",
       "      <td>irr</td>\n",
       "      <td>5545.67</td>\n",
       "      <td>POLYGON ((76.40937 15.19414, 76.40658 15.19403...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Season Insurance Unit      shapeName Gram Panchayat/Hobli District  \\\n",
       "0  2017  Kharif  114. danapura  114. danapura                   gp  ballari   \n",
       "\n",
       "    Taluk   Crop IRR_RF  Average Yield(Kg/Ha)  \\\n",
       "0  hospet  paddy    irr               5545.67   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((76.40937 15.19414, 76.40658 15.19403...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_calculation = yields_geometries.sort_values(['shapeName'], ascending=True, ignore_index=True)\n",
    "obs_calculation.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hobli_names_taluk = df_hobli_taluk[['shapeName', 'KGISTalukN']].sort_values(['shapeName', 'KGISTalukN'])\n",
    "# grampan_names_taluk = df_grampan_taluk[['shapeName', 'KGISTalukN']].sort_values(['shapeName', 'KGISTalukN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hobli_gdf = gpd.GeoDataFrame(hobli, geometry = hobli.geometry, crs = {'init': 'epsg:32643'}) # 32643 is the original crs (found by using .crs for one of the input shp files)\n",
    "# grampan_gdf = gpd.GeoDataFrame(grampan, geometry = grampan.geometry, crs = {'init': 'epsg:32643'}) # 32643 is the original crs (found by using .crs for one of the input shp files)\n",
    "\n",
    "# hobli_gdf.to_file(r'C:\\Users\\mieke\\Documents\\Msc Thesis\\Notebooks Python\\hobli.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "# grampan_gdf.to_file(r'C:\\Users\\mieke\\Documents\\Msc Thesis\\Notebooks Python\\grampan.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yields[(yields['Insurance Unit'].isin(list(check_grampan6['shapeName'])))] # 1011\n",
    "# #yields[(yields['Insurance Unit'].isin(list(check_grampan6['shapeName']))) & (yields['Crop'] == 'paddy')] # 322\n",
    "# #yields[(yields['Insurance Unit'].isin(list(check_grampan6['shapeName']))) & (yields['Crop'] == 'maize (makka)')] # 360\n",
    "# #yields[(yields['Insurance Unit'].isin(list(check_grampan6['shapeName']))) & (yields['Crop'] == 'sorghum (jowar/great millet)')] # 329\n",
    "\n",
    "# # Eventueel kunnen we nog de similarity > 95 meenemen\n",
    "# check_grampan6[check_grampan6['Similarity'] >= 94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = yields.groupby(['Insurance Unit', 'Gram Panchayat/Hobli', 'Taluk', 'District'])\n",
    "# keys = g.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yields_paddy = yields[yields['Crop'] == 'paddy']\n",
    "# g = yields_paddy.groupby('Insurance Unit')\n",
    "# keys = list(g.groups.keys())\n",
    "# g.get_group(keys[7]) # .count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCRAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2482\n",
      "2160\n",
      "1962\n",
      "\n",
      "\n",
      "2381\n",
      "2089\n",
      "1892\n"
     ]
    }
   ],
   "source": [
    "print(len(yields[yields['Crop'] == 'paddy']['Insurance Unit'].unique()))\n",
    "print(len(yields[yields['Crop'] == 'maize (makka)']['Insurance Unit'].unique()))\n",
    "print(len(yields[yields['Crop'] == 'sorghum (jowar/great millet)']['Insurance Unit'].unique()))\n",
    "print('\\n')\n",
    "print(len(yields_geometries[yields_geometries['Crop'] == 'paddy']['Insurance Unit'].unique()))\n",
    "print(len(yields_geometries[yields_geometries['Crop'] == 'maize (makka)']['Insurance Unit'].unique()))\n",
    "print(len(yields_geometries[yields_geometries['Crop'] == 'sorghum (jowar/great millet)']['Insurance Unit'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=225\n",
    "# gdp_temp = taluk_district[taluk_district['District'] == df_grampan.loc[i, 'District']] # select taluks within the district for i\n",
    "# selected = df_grampan[(df_grampan['shapeName'] == df_grampan.loc[i,'shapeName']) & (df_grampan['District'] == df_grampan.loc[i,'District']) & (df_grampan['geometry'] == df_grampan.loc[i,'geometry'])]\n",
    "# gpd_join_temp = gpd.overlay(selected, gpd_temp, how='intersection')\n",
    "# gpd_join_temp\n",
    "# # df_join_temp = gpd.sjoin(selected, gdp_temp, how='left', predicate='intersects')\n",
    "# # df_join_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geopandas.overlay(df1, df2, how='intersection', keep_geom_type=None, make_valid=True)\n",
    "# Misschien kunnen we een loop schrijven die per gram panchayat checkt welke taluks ie intersect. Maar dan wel alleen voor de taluks binnen het bijbehorende district\n",
    "# df_gp_taluk = gpd.GeoDataFrame()\n",
    "# lengths = []\n",
    "# for i in df_grampan.index:\n",
    "#     gpd_temp = taluk_district[taluk_district['District'] == df_grampan.loc[i, 'District']] # select taluks within the district for i\n",
    "#     selected = df_grampan[(df_grampan['shapeName'] == df_grampan.loc[i,'shapeName']) & (df_grampan['District'] == df_grampan.loc[i,'District'])]\n",
    "#     gpd_join_temp = gpd.overlay(selected, gpd_temp, how='intersection')\n",
    "#     df_gp_taluk = pd.concat([df_gp_taluk, gpd_join_temp], ignore_index = True)\n",
    "#     lengths.append(np.size(selected,0))\n",
    "\n",
    "# df_gp_taluk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misschien kunnen we een loop schrijven die per gram panchayat checkt welke taluks ie intersect. Maar dan wel alleen voor de taluks binnen het bijbehorende district\n",
    "# df_gp_taluk = gpd.GeoDataFrame()\n",
    "# lengths = []\n",
    "# for i in df_grampan.index:\n",
    "#     gpd_temp = taluk_district[taluk_district['District'] == df_grampan.loc[i, 'District']] # select taluks within the district for i\n",
    "#     selected = df_grampan[(df_grampan['shapeName'] == df_grampan.loc[i,'shapeName']) & (df_grampan['District'] == df_grampan.loc[i,'District']) & (df_grampan['geometry'] == df_grampan.loc[i,'geometry'])]\n",
    "#     gpd_join_temp = gpd.sjoin(selected, gpd_temp, how='left', predicate='intersects')\n",
    "#     df_gp_taluk = pd.concat([df_gp_taluk, gpd_join_temp], ignore_index = True)\n",
    "#     lengths.append(np.size(selected,0))\n",
    "\n",
    "# df_gp_taluk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# p = np.array(gpd_join_temp1[(gpd_join_temp1['geometry'] == gpd_join_temp1.loc[i, 'geometry'])]['geometry'])[0]\n",
    "# q = np.array(taluk_district[(taluk_district['District'] == gpd_join_temp1.loc[i, 'District_left']) & (taluk_district['KGISTalukN'] == gpd_join_temp1.loc[i, 'KGISTalukN'])]['geometry'])[0]\n",
    "\n",
    "# p.intersection(q).area"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('thesis_base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "734205a0c94b5e97d2e885f269ea6bd400da4ba9a6c87b08a93b97fdaab1acc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
