{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import re\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from rasterstats import zonal_stats\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "import rasterstats\n",
    "import time\n",
    "sys.path.append(os.path.abspath(\"C:/Users/mieke/Documents/Msc Thesis/Notebooks Python/Final/\"))\n",
    "import functions_model #import python file containing the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For updates\n",
    "import importlib\n",
    "importlib.reload(functions_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a shapeName column containing the names of each Insurance Unit in lowercase and stripped\n",
    "insurance_names = gpd.read_file(r'C:\\Users\\mieke\\Documents\\Msc Thesis\\Notebooks Python\\Final\\insurance_names.geojson')\n",
    "insurance_names['shapeName'] = insurance_names['Insurance Unit'].copy()\n",
    "insurance_names.shapeName = insurance_names.shapeName.str.lower()\n",
    "insurance_names.shapeName = insurance_names.shapeName.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "yields = gpd.read_file(r'C:\\Users\\mieke\\Documents\\Msc Thesis\\Notebooks Python\\Final\\yields_geometry.geojson') # All yield observations for paddy, maize and soghrum\n",
    "obs_calculation = gpd.read_file(r'C:\\Users\\mieke\\Documents\\Msc Thesis\\Notebooks Python\\Final\\obs_calculation.geojson') # All unique geometries for each crop type per year, season, unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_paddy = obs_calculation[obs_calculation['Crop'] == 'paddy'] # 7285\n",
    "obs_maize = obs_calculation[obs_calculation['Crop'] == 'maize (makka)'] # 6008\n",
    "obs_sorghum = obs_calculation[obs_calculation['Crop'] == 'sorghum (jowar/great millet)'] # 4788\n",
    "\n",
    "yields_paddy = yields[yields['Crop'] == 'paddy'] # 8461\n",
    "yields_maize = yields[yields['Crop'] == 'maize (makka)'] # 7480 \n",
    "yields_sorghum = yields[yields['Crop'] == 'sorghum (jowar/great millet)'] # 5411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields_copy = yields.copy()\n",
    "obs_calculation_copy = obs_calculation.copy()\n",
    "# yields = yields_copy.copy()\n",
    "# obs_calculation = obs_calculation_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.size(yields_maize[yields_maize['Season'] == 'Rabi'],0)) # 819\n",
    "print(np.size(yields_maize[yields_maize['Season'] == 'Summer'],0)) # 51\n",
    "print(np.size(yields_maize[yields_maize['Season'] == 'Kharif'],0), '\\n') # 6610\n",
    "\n",
    "print(np.size(yields_sorghum[yields_sorghum['Season'] == 'Rabi'],0)) # 4636\n",
    "print(np.size(yields_sorghum[yields_sorghum['Season'] == 'Summer'],0)) # 8\n",
    "print(np.size(yields_sorghum[yields_sorghum['Season'] == 'Kharif'],0), '\\n') # 767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes per season per year such that we can calculate statistics based on this information (e.g. parameter value differs per year, season)\n",
    "maize_2016_rabi = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Rabi')] # 241\n",
    "maize_2016_zaid = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Summer')] # 23\n",
    "maize_2016_kharif = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Kharif')] # 1916\n",
    "maize_2017_rabi = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Rabi')] # 251\n",
    "maize_2017_zaid = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Summer')] # 16\n",
    "maize_2017_kharif = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Kharif')] # 1760\n",
    "maize_2018_rabi = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Rabi')] # 225\n",
    "maize_2018_zaid = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Summer')] # 8\n",
    "maize_2018_kharif = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Kharif')] # 1568\n",
    "\n",
    "sorghum_2016_rabi = obs_sorghum[(obs_sorghum['Year'] == 2016) & (obs_sorghum['Season'] == 'Rabi')] # 1168\n",
    "sorghum_2016_zaid = obs_sorghum[(obs_sorghum['Year'] == 2016) & (obs_sorghum['Season'] == 'Summer')] # 4\n",
    "sorghum_2016_kharif = obs_sorghum[(obs_sorghum['Year'] == 2016) & (obs_sorghum['Season'] == 'Kharif')] # 207\n",
    "sorghum_2017_rabi = obs_sorghum[(obs_sorghum['Year'] == 2017) & (obs_sorghum['Season'] == 'Rabi')] # 1632\n",
    "sorghum_2017_zaid = obs_sorghum[(obs_sorghum['Year'] == 2017) & (obs_sorghum['Season'] == 'Summer')] # 1\n",
    "sorghum_2017_kharif = obs_sorghum[(obs_sorghum['Year'] == 2017) & (obs_sorghum['Season'] == 'Kharif')] # 163\n",
    "sorghum_2018_rabi = obs_sorghum[(obs_sorghum['Year'] == 2018) & (obs_sorghum['Season'] == 'Rabi')] # 1568\n",
    "sorghum_2018_zaid = obs_sorghum[(obs_sorghum['Year'] == 2018) & (obs_sorghum['Season'] == 'Summer')] # 0\n",
    "sorghum_2018_kharif = obs_sorghum[(obs_sorghum['Year'] == 2018) & (obs_sorghum['Season'] == 'Kharif')] # 134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.size(maize_2016_rabi,0)) # 184\n",
    "print(np.size(maize_2016_zaid,0)) # 210\n",
    "print(np.size(maize_2016_kharif,0))# 2098\n",
    "print(np.size(maize_2017_rabi,0)) # 222\n",
    "print(np.size(maize_2017_zaid,0)) # 380\n",
    "print(np.size(maize_2017_kharif,0)) # 1739\n",
    "print(np.size(maize_2018_rabi,0)) # 192\n",
    "print(np.size(maize_2018_zaid,0)) # 387\n",
    "print(np.size(maize_2018_kharif,0), '\\n') # 1873\n",
    "\n",
    "print(np.size(sorghum_2016_rabi,0)) # 184\n",
    "print(np.size(sorghum_2016_zaid,0)) # 210\n",
    "print(np.size(sorghum_2016_kharif,0)) # 2098\n",
    "print(np.size(sorghum_2017_rabi,0)) # 222\n",
    "print(np.size(sorghum_2017_zaid,0)) # 380\n",
    "print(np.size(sorghum_2017_kharif,0)) # 1739\n",
    "print(np.size(sorghum_2018_rabi,0)) # 192\n",
    "print(np.size(sorghum_2018_zaid,0)) # 387\n",
    "print(np.size(sorghum_2018_kharif,0)) # 1873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates monthly averages for each parameter of interest and stores them in folder init_path\n",
    "beginyear = 2015\n",
    "endyear = 2018\n",
    "paths = ['D:/Data_download/GEE/NDVI/Karnataka/cropmask/', 'D:/Data_download/GEE/EVI/Karnataka/cropmask/', 'D:/Data_download/Copernicus/FAPAR/Karnataka/cropmask/', 'D:/Data_download/Copernicus/LAI/Karnataka/cropmask/', 'D:/Data_download/Other/SIF/Karnataka/cropmask/', 'D:/Data_download/GEE/SSM/Karnataka/cropmask/', 'D:/Data_download/GEE/SUSM/Karnataka/cropmask/', 'D:/Data_download/GEE/LST/Karnataka/cropmask/', 'D:/Data_download/GEE/LSTN/Karnataka/cropmask/', 'D:/Data_download/GEE/Precipitation/Karnataka/cropmask/']\n",
    "init_path = 'D:/monthly_images/crop/'\n",
    "parameters = ['NDVI', 'EVI', 'FAPAR', 'LAI', 'SIF', 'SSM', 'SUSM', 'LST', 'LSTN', 'Precipitation']\n",
    "for i in range(len(parameters)):\n",
    "    dest_path = init_path + parameters[i] + '/'\n",
    "    # if i == 'Precipitation':\n",
    "    #     monthly_accumulates(paths[i], dest_path, beginyear, endyear)\n",
    "    # else:\n",
    "    functions_model.monthly_averages(paths[i], dest_path, beginyear, endyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell sets values for the parameters we use for function time_observations within the next cell\n",
    "paths = ['D:/monthly_images/crop/NDVI/', 'D:/monthly_images/crop/EVI/', 'D:/monthly_images/crop/FAPAR/', 'D:/monthly_images/crop/LAI/', 'D:/monthly_images/crop/SIF/', 'D:/monthly_images/crop/SSM/', 'D:/monthly_images/crop/SUSM/', 'D:/monthly_images/crop/LST/', 'D:/monthly_images/crop/LSTN/', 'D:/monthly_images/crop/Precipitation/']\n",
    "methods = [False, False, False, False, True, True, True, False, False, True]\n",
    "statistic = ['median']\n",
    "parameters = ['NDVI', 'EVI', 'FAPAR', 'LAI', 'SIF', 'SSM', 'SUSM', 'LST', 'LSTN', 'Precipitation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates a dataframe where we have the following information per observation:\n",
    "# all monthly values for each parameter during the corresponding year and season \n",
    "for i in range(len(parameters)):\n",
    "    maize_2016_rabi = functions_model.time_observations(maize_2016_rabi, parameters[i], paths[i], statistic, methods[i])\n",
    "    maize_2017_rabi = functions_model.time_observations(maize_2017_rabi, parameters[i], paths[i], statistic, methods[i])\n",
    "    maize_2018_rabi = functions_model.time_observations(maize_2018_rabi, parameters[i], paths[i], statistic, methods[i])\n",
    "\n",
    "    maize_2016_kharif = functions_model.time_observations(maize_2016_kharif, parameters[i], paths[i], statistic, methods[i])\n",
    "    maize_2017_kharif = functions_model.time_observations(maize_2017_kharif, parameters[i], paths[i], statistic, methods[i])\n",
    "    maize_2018_kharif = functions_model.time_observations(maize_2018_kharif, parameters[i], paths[i], statistic, methods[i])\n",
    "    print(parameters[i] + ' added.')\n",
    "maize_rabi = pd.concat([maize_2016_rabi, maize_2017_rabi, maize_2018_rabi], ignore_index=True)\n",
    "maize_kharif = pd.concat([maize_2016_kharif, maize_2017_kharif, maize_2018_kharif], ignore_index=True)\n",
    "# Time: 20 min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    }
   ],
   "source": [
    "# Save these dataframes to a geoJSON\n",
    "maize_rabi.to_file(r'D:\\other_thesis\\maize_rabi_false.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "maize_kharif.to_file(r'D:\\other_thesis\\maize_kharif_false.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = ['D:/monthly_images/crop/NDVI/', 'D:/monthly_images/crop/EVI/', 'D:/monthly_images/crop/FAPAR/', 'D:/monthly_images/crop/LAI/', 'D:/monthly_images/crop/SIF/', 'D:/monthly_images/crop/SSM/', 'D:/monthly_images/crop/SUSM/', 'D:/monthly_images/crop/LST/', 'D:/monthly_images/crop/LSTN/', 'D:/monthly_images/crop/Precipitation/']\n",
    "# methods = [False, False, False, False, True, True, True, True, True, True]\n",
    "# statistic = ['median']\n",
    "# parameters = ['NDVI', 'EVI', 'FAPAR', 'LAI', 'SIF', 'SSM', 'SUSM', 'LST', 'LSTN', 'Precipitation']\n",
    "\n",
    "# maize_2016_rabi = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Rabi')] # 241\n",
    "# maize_2016_zaid = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Summer')] # 23\n",
    "# maize_2016_kharif = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Kharif')] # 1916\n",
    "# maize_2017_rabi = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Rabi')] # 251\n",
    "# maize_2017_zaid = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Summer')] # 16\n",
    "# maize_2017_kharif = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Kharif')] # 1760\n",
    "# maize_2018_rabi = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Rabi')] # 225\n",
    "# maize_2018_zaid = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Summer')] # 8\n",
    "# maize_2018_kharif = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Kharif')] # 1568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI added.\n",
      "EVI added.\n",
      "FAPAR added.\n",
      "LAI added.\n",
      "SIF added.\n",
      "SSM added.\n",
      "SUSM added.\n",
      "LST added.\n",
      "LSTN added.\n",
      "Precipitation added.\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(parameters)):\n",
    "#     maize_2016_rabi = functions_model.time_observations(maize_2016_rabi, parameters[i], paths[i], statistic, methods[i])\n",
    "#     maize_2017_rabi = functions_model.time_observations(maize_2017_rabi, parameters[i], paths[i], statistic, methods[i])\n",
    "#     maize_2018_rabi = functions_model.time_observations(maize_2018_rabi, parameters[i], paths[i], statistic, methods[i])\n",
    "\n",
    "#     maize_2016_kharif = functions_model.time_observations(maize_2016_kharif, parameters[i], paths[i], statistic, methods[i])\n",
    "#     maize_2017_kharif = functions_model.time_observations(maize_2017_kharif, parameters[i], paths[i], statistic, methods[i])\n",
    "#     maize_2018_kharif = functions_model.time_observations(maize_2018_kharif, parameters[i], paths[i], statistic, methods[i])\n",
    "#     print(parameters[i] + ' added.')\n",
    "# maize_rabi = pd.concat([maize_2016_rabi, maize_2017_rabi, maize_2018_rabi], ignore_index=True)\n",
    "# maize_kharif = pd.concat([maize_2016_kharif, maize_2017_kharif, maize_2018_kharif], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    }
   ],
   "source": [
    "# # True wrt LST and LSTN\n",
    "# maize_rabi.to_file(r'D:\\other_thesis\\maize_rabi_true.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "# maize_kharif.to_file(r'D:\\other_thesis\\maize_kharif_true.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07220061022120519\n",
      "0.003399581589958159\n"
     ]
    }
   ],
   "source": [
    "# With some Falses\n",
    "maize_kharif.isna().sum().sum() # 18931\n",
    "maize_rabi.isna().sum().sum() # 195\n",
    "\n",
    "np.size(maize_kharif.iloc[:,11:]) # 262200\n",
    "print(18931/262200) # 0.07220061022120519 (percentage of missing values within the kharif season)\n",
    "np.size(maize_rabi.iloc[:,11:]) # 57360\n",
    "print(195/57360) # 0.003399581589958159 (percentage of missing values within the rabi season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell investigates the NaN-values within the dataframe\n",
    "maize_kharif.iloc[:,11:16] # NDVI\n",
    "maize_kharif.iloc[:,16:21] # EVI\n",
    "maize_kharif.iloc[:,21:26] # FAPAR\n",
    "maize_kharif.iloc[:,26:31] # LAI\n",
    "maize_kharif.iloc[:,31:36] # SIF\n",
    "maize_kharif.iloc[:,36:41] # SSM\n",
    "maize_kharif.iloc[:,41:46] # SUSM\n",
    "maize_kharif.iloc[:,46:51] # LST\n",
    "maize_kharif.iloc[:,51:56] # LSTN\n",
    "\n",
    "maize_kharif.iloc[:,11:16][maize_kharif.iloc[:,11:16].isna().sum(axis=1) == 5] # NDVI, 3 (405, 2287, 4007), False\n",
    "maize_kharif.iloc[:,16:21][maize_kharif.iloc[:,16:21].isna().sum(axis=1) == 5] # EVI, 3 (405, 2287, 4007), False\n",
    "maize_kharif.iloc[:,21:26][maize_kharif.iloc[:,21:26].isna().sum(axis=1) == 5] # FAPAR 3 (405, 2287, 4007), False\n",
    "maize_kharif.iloc[:,26:31][maize_kharif.iloc[:,26:31].isna().sum(axis=1) == 5] # LAI 3 (405, 2287, 4007), False\n",
    "maize_kharif.iloc[:,31:36][maize_kharif.iloc[:,31:36].isna().sum(axis=1) == 5] # SIF 121 (among 405, 2287, 4007), True\n",
    "maize_kharif.iloc[:,36:41][maize_kharif.iloc[:,36:41].isna().sum(axis=1) == 5] # SSM 190 (among 405, 2287, 4007), True\n",
    "maize_kharif.iloc[:,41:46][maize_kharif.iloc[:,41:46].isna().sum(axis=1) == 5] # SUSM 190 (among 405, 2287, 4007), True\n",
    "maize_kharif.iloc[:,46:51][maize_kharif.iloc[:,46:51].isna().sum(axis=1) == 5] # LST 19 (among 405, 2287, 4007), False (Deze zouden we eventueel nog kunnen switchen)\n",
    "maize_kharif.iloc[:,51:56][maize_kharif.iloc[:,51:56].isna().sum(axis=1) == 5] # LSTN 19 (among 405, 2287, 4007), False (Deze zouden we eventueel nog kunnen switchen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe observations\n",
    "maize_2016_rabi = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Rabi')] # 241\n",
    "maize_2016_zaid = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Summer')] # 23\n",
    "maize_2016_kharif = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Kharif')] # 1916\n",
    "maize_2017_rabi = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Rabi')] # 251\n",
    "maize_2017_zaid = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Summer')] # 16\n",
    "maize_2017_kharif = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Kharif')] # 1760\n",
    "maize_2018_rabi = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Rabi')] # 225\n",
    "maize_2018_zaid = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Summer')] # 8\n",
    "maize_2018_kharif = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Kharif')] # 1568\n",
    "\n",
    "maize_2016_rabi.to_file(r'D:\\other_thesis\\maize_2016_rabi.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "maize_2016_zaid.to_file(r'D:\\other_thesis\\maize_2016_zaid.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "maize_2016_kharif.to_file(r'D:\\other_thesis\\maize_2016_kharif.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "maize_2017_rabi.to_file(r'D:\\other_thesis\\maize_2017_rabi.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "maize_2017_zaid.to_file(r'D:\\other_thesis\\maize_2017_zaid.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "maize_2017_kharif.to_file(r'D:\\other_thesis\\maize_2017_kharif.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "maize_2018_rabi.to_file(r'D:\\other_thesis\\maize_2018_rabi.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "maize_2018_zaid.to_file(r'D:\\other_thesis\\maize_2018_zaid.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "maize_2018_kharif.to_file(r'D:\\other_thesis\\maize_2018_kharif.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates a dataframe where we have the following information per observation:\n",
    "# all daily values for Precipitation during the corresponding year and season \n",
    "maize_2016_rabi = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Rabi')] # 241\n",
    "maize_2016_zaid = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Summer')] # 23\n",
    "maize_2016_kharif = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Kharif')] # 1916\n",
    "maize_2017_rabi = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Rabi')] # 251\n",
    "maize_2017_zaid = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Summer')] # 16\n",
    "maize_2017_kharif = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Kharif')] # 1760\n",
    "maize_2018_rabi = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Rabi')] # 225\n",
    "maize_2018_zaid = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Summer')] # 8\n",
    "maize_2018_kharif = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Kharif')] # 1568\n",
    "\n",
    "path_pre = 'D:/Data_download/GEE/Precipitation/Karnataka/cropmask/'\n",
    "\n",
    "maize_2016_rabi = functions_model.time_observations_day(maize_2016_rabi, parameters[-1], path_pre, statistic, methods[-1]) # 4 min \n",
    "print('maize_2016_rabi done.')\n",
    "maize_2017_rabi = functions_model.time_observations_day(maize_2017_rabi, parameters[-1], path_pre, statistic, methods[-1])\n",
    "print('maize_2017_rabi done.')\n",
    "maize_2018_rabi = functions_model.time_observations_day(maize_2018_rabi, parameters[-1], path_pre, statistic, methods[-1])\n",
    "print('maize_2018_rabi done.')\n",
    "maize_2016_kharif = functions_model.time_observations_day(maize_2016_kharif, parameters[-1], path_pre, statistic, methods[-1])\n",
    "print('maize_2016_kharif done.')\n",
    "maize_2017_kharif = functions_model.time_observations_day(maize_2017_kharif, parameters[-1], path_pre, statistic, methods[-1])\n",
    "print('maize_2017_kharif done.')\n",
    "maize_2018_kharif = functions_model.time_observations_day(maize_2018_kharif, parameters[-1], path_pre, statistic, methods[-1])\n",
    "print('maize_2018_kharif done.')\n",
    "maize_rabi_precipitation = pd.concat([maize_2016_rabi, maize_2017_rabi, maize_2018_rabi], ignore_index=True)\n",
    "maize_kharif_precipitation = pd.concat([maize_2016_kharif, maize_2017_kharif, maize_2018_kharif], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    }
   ],
   "source": [
    "# Save these dataframes\n",
    "maize_rabi_precipitation.to_file(r'D:\\other_thesis\\maize_rabi_precipitation.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "maize_kharif_precipitation.to_file(r'D:\\other_thesis\\maize_kharif_precipitation.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wel average voor: \n",
    "# LAI, (gemiddelde over drie images) OK\n",
    "# NDVI, EVI (gemiddelde over twee images) OK\n",
    "# SIF, (gemiddelde over twee images) OK\n",
    "# FAPAR, (gemiddelde over drie images) OK \n",
    "# NIET OK:\n",
    "# LST, LSTN, (gemiddelde over 30 images) Hier missen heel veel values, dus wellicht wel een goede approach hier\n",
    "# SSM, SUSM (gemiddelde over 10 images)\n",
    "# Voor precipitation de som gebruiken ipv average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maize_2016_rabi done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maize_2017_rabi done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maize_2018_rabi done.\n",
      "maize_2016_kharif done.\n",
      "maize_2017_kharif done.\n",
      "maize_2018_kharif done.\n"
     ]
    }
   ],
   "source": [
    "# This cell creates a dataframe where we have the following information per observation:\n",
    "# all monthly values for SSM during the corresponding year and season \n",
    "maize_2016_rabi = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Rabi')] # 241\n",
    "maize_2016_zaid = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Summer')] # 23\n",
    "maize_2016_kharif = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Kharif')] # 1916\n",
    "maize_2017_rabi = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Rabi')] # 251\n",
    "maize_2017_zaid = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Summer')] # 16\n",
    "maize_2017_kharif = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Kharif')] # 1760\n",
    "maize_2018_rabi = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Rabi')] # 225\n",
    "maize_2018_zaid = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Summer')] # 8\n",
    "maize_2018_kharif = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Kharif')] # 1568\n",
    "\n",
    "path_pre = 'D:/Data_download/GEE/SSM/Karnataka/cropmask/'\n",
    "\n",
    "maize_2016_rabi = functions_model.time_observations_day(maize_2016_rabi, 'SSM', path_pre, statistic, True) # 4 min \n",
    "print('maize_2016_rabi done.')\n",
    "maize_2017_rabi = functions_model.time_observations_day(maize_2017_rabi, 'SSM', path_pre, statistic, True)\n",
    "print('maize_2017_rabi done.')\n",
    "maize_2018_rabi = functions_model.time_observations_day(maize_2018_rabi, 'SSM', path_pre, statistic, True)\n",
    "print('maize_2018_rabi done.')\n",
    "maize_2016_kharif = functions_model.time_observations_day(maize_2016_kharif, 'SSM', path_pre, statistic, True)\n",
    "print('maize_2016_kharif done.')\n",
    "maize_2017_kharif = functions_model.time_observations_day(maize_2017_kharif, 'SSM', path_pre, statistic, True)\n",
    "print('maize_2017_kharif done.')\n",
    "maize_2018_kharif = functions_model.time_observations_day(maize_2018_kharif, 'SSM', path_pre, statistic, True)\n",
    "print('maize_2018_kharif done.')\n",
    "maize_rabi_ssm = pd.concat([maize_2016_rabi, maize_2017_rabi, maize_2018_rabi], ignore_index=True)\n",
    "maize_kharif_ssm = pd.concat([maize_2016_kharif, maize_2017_kharif, maize_2018_kharif], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    }
   ],
   "source": [
    "# Save these dataframes\n",
    "maize_rabi_ssm.to_file(r'D:\\other_thesis\\maize_rabi_ssm.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "maize_kharif_ssm.to_file(r'D:\\other_thesis\\maize_kharif_ssm.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maize_2016_rabi done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maize_2017_rabi done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\geodataframe.py:1351: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maize_2018_rabi done.\n",
      "maize_2016_kharif done.\n",
      "maize_2017_kharif done.\n",
      "maize_2018_kharif done.\n"
     ]
    }
   ],
   "source": [
    "# This cell creates a dataframe where we have the following information per observation:\n",
    "# all monthly values for SUSM during the corresponding year and season \n",
    "maize_2016_rabi = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Rabi')] # 241\n",
    "maize_2016_zaid = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Summer')] # 23\n",
    "maize_2016_kharif = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Kharif')] # 1916\n",
    "maize_2017_rabi = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Rabi')] # 251\n",
    "maize_2017_zaid = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Summer')] # 16\n",
    "maize_2017_kharif = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Kharif')] # 1760\n",
    "maize_2018_rabi = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Rabi')] # 225\n",
    "maize_2018_zaid = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Summer')] # 8\n",
    "maize_2018_kharif = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Kharif')] # 1568\n",
    "\n",
    "path_pre = 'D:/Data_download/GEE/SUSM/Karnataka/cropmask/'\n",
    "\n",
    "maize_2016_rabi = functions_model.time_observations_day(maize_2016_rabi, 'SUSM', path_pre, statistic, True) # 4 min \n",
    "print('maize_2016_rabi done.')\n",
    "maize_2017_rabi = functions_model.time_observations_day(maize_2017_rabi, 'SUSM', path_pre, statistic, True)\n",
    "print('maize_2017_rabi done.')\n",
    "maize_2018_rabi = functions_model.time_observations_day(maize_2018_rabi, 'SUSM', path_pre, statistic, True)\n",
    "print('maize_2018_rabi done.')\n",
    "maize_2016_kharif = functions_model.time_observations_day(maize_2016_kharif, 'SUSM', path_pre, statistic, True)\n",
    "print('maize_2016_kharif done.')\n",
    "maize_2017_kharif = functions_model.time_observations_day(maize_2017_kharif, 'SUSM', path_pre, statistic, True)\n",
    "print('maize_2017_kharif done.')\n",
    "maize_2018_kharif = functions_model.time_observations_day(maize_2018_kharif, 'SUSM', path_pre, statistic, True)\n",
    "print('maize_2018_kharif done.')\n",
    "maize_rabi_susm = pd.concat([maize_2016_rabi, maize_2017_rabi, maize_2018_rabi], ignore_index=True)\n",
    "maize_kharif_susm = pd.concat([maize_2016_kharif, maize_2017_kharif, maize_2018_kharif], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    }
   ],
   "source": [
    "# Save these dataframes\n",
    "maize_rabi_susm.to_file(r'D:\\other_thesis\\maize_rabi_susm.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "maize_kharif_susm.to_file(r'D:\\other_thesis\\maize_kharif_susm.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells are aggregating irr and rf yields such that we can visualize the average yields (kg/ha) as a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields_maize_2016_rabi = yields_maize[(yields_maize['Year'] == 2016) & (yields_maize['Season'] == 'Rabi')] # 241\n",
    "yields_maize_2016_zaid = yields_maize[(yields_maize['Year'] == 2016) & (yields_maize['Season'] == 'Summer')] # 23\n",
    "yields_maize_2016_kharif = yields_maize[(yields_maize['Year'] == 2016) & (yields_maize['Season'] == 'Kharif')] # 1916\n",
    "yields_maize_2017_rabi = yields_maize[(yields_maize['Year'] == 2017) & (yields_maize['Season'] == 'Rabi')] # 251\n",
    "yields_maize_2017_zaid = yields_maize[(yields_maize['Year'] == 2017) & (yields_maize['Season'] == 'Summer')] # 16\n",
    "yields_maize_2017_kharif = yields_maize[(yields_maize['Year'] == 2017) & (yields_maize['Season'] == 'Kharif')] # 1760\n",
    "yields_maize_2018_rabi = yields_maize[(yields_maize['Year'] == 2018) & (yields_maize['Season'] == 'Rabi')] # 225\n",
    "yields_maize_2018_zaid = yields_maize[(yields_maize['Year'] == 2018) & (yields_maize['Season'] == 'Summer')] # 8\n",
    "yields_maize_2018_kharif = yields_maize[(yields_maize['Year'] == 2018) & (yields_maize['Season'] == 'Kharif')] # 1568\n",
    "\n",
    "yields_maize_2016_rabi_agg = yields_maize_2016_rabi.groupby(['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])['Average Yield(Kg/Ha)'].agg('sum').reset_index()\n",
    "yields_maize_2016_zaid_agg = yields_maize_2016_zaid.groupby(['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])['Average Yield(Kg/Ha)'].agg('sum').reset_index()\n",
    "yields_maize_2016_kharif_agg = yields_maize_2016_kharif.groupby(['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])['Average Yield(Kg/Ha)'].agg('sum').reset_index()\n",
    "yields_maize_2017_rabi_agg = yields_maize_2017_rabi.groupby(['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])['Average Yield(Kg/Ha)'].agg('sum').reset_index()\n",
    "yields_maize_2017_zaid_agg = yields_maize_2017_zaid.groupby(['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])['Average Yield(Kg/Ha)'].agg('sum').reset_index()\n",
    "yields_maize_2017_kharif_agg = yields_maize_2017_kharif.groupby(['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])['Average Yield(Kg/Ha)'].agg('sum').reset_index()\n",
    "yields_maize_2018_rabi_agg = yields_maize_2018_rabi.groupby(['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])['Average Yield(Kg/Ha)'].agg('sum').reset_index()\n",
    "yields_maize_2018_zaid_agg = yields_maize_2018_zaid.groupby(['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])['Average Yield(Kg/Ha)'].agg('sum').reset_index()\n",
    "yields_maize_2018_kharif_agg = yields_maize_2018_kharif.groupby(['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])['Average Yield(Kg/Ha)'].agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\pyproj\\crs\\crs.py:130: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\pyproj\\crs\\crs.py:130: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\pyproj\\crs\\crs.py:130: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    }
   ],
   "source": [
    "yields_maize_2016_rabi_agg = yields_maize_2016_rabi_agg.merge(yields_maize_2016_rabi, how = 'inner', on = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])\n",
    "yields_maize_2016_rabi_agg = yields_maize_2016_rabi_agg.iloc[:,[0,1,2,3,4,5,6,11]]\n",
    "yields_maize_2016_rabi_agg = yields_maize_2016_rabi_agg.rename(columns = {'Average Yield(Kg/Ha)_x': 'Average Yield(Kg/Ha)', 'geometry_x': 'geometry'})\n",
    "yields_maize_2016_rabi_agg  = gpd.GeoDataFrame(yields_maize_2016_rabi_agg, geometry = yields_maize_2016_rabi_agg.geometry, crs = {'init': 'epsg:4326'})\n",
    "yields_maize_2016_rabi_agg = yields_maize_2016_rabi_agg.drop_duplicates(ignore_index=True)#subset = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk', ''], ignore_index=True)\n",
    "\n",
    "yields_maize_2016_kharif_agg = yields_maize_2016_kharif_agg.merge(yields_maize_2016_kharif, how = 'inner', on = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])\n",
    "yields_maize_2016_kharif_agg = yields_maize_2016_kharif_agg.iloc[:,[0,1,2,3,4,5,6,11]]\n",
    "yields_maize_2016_kharif_agg = yields_maize_2016_kharif_agg.rename(columns = {'Average Yield(Kg/Ha)_x': 'Average Yield(Kg/Ha)', 'geometry_x': 'geometry'})\n",
    "yields_maize_2016_kharif_agg  = gpd.GeoDataFrame(yields_maize_2016_kharif_agg, geometry = yields_maize_2016_kharif_agg.geometry, crs = {'init': 'epsg:4326'})\n",
    "yields_maize_2016_kharif_agg = yields_maize_2016_kharif_agg.drop_duplicates(ignore_index=True)#subset = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk', ''], ignore_index=True)\n",
    "\n",
    "yields_maize_2016_zaid_agg = yields_maize_2016_zaid_agg.merge(yields_maize_2016_zaid, how = 'inner', on = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])\n",
    "yields_maize_2016_zaid_agg = yields_maize_2016_zaid_agg.iloc[:,[0,1,2,3,4,5,6,11]]\n",
    "yields_maize_2016_zaid_agg = yields_maize_2016_zaid_agg.rename(columns = {'Average Yield(Kg/Ha)_x': 'Average Yield(Kg/Ha)', 'geometry_x': 'geometry'})\n",
    "yields_maize_2016_zaid_agg  = gpd.GeoDataFrame(yields_maize_2016_zaid_agg, geometry = yields_maize_2016_zaid_agg.geometry, crs = {'init': 'epsg:4326'})\n",
    "yields_maize_2016_zaid_agg = yields_maize_2016_zaid_agg.drop_duplicates(ignore_index=True)#subset = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk', ''], ignore_index=True)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\pyproj\\crs\\crs.py:130: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\pyproj\\crs\\crs.py:130: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\pyproj\\crs\\crs.py:130: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    }
   ],
   "source": [
    "yields_maize_2017_rabi_agg = yields_maize_2017_rabi_agg.merge(yields_maize_2017_rabi, how = 'inner', on = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])\n",
    "yields_maize_2017_rabi_agg = yields_maize_2017_rabi_agg.iloc[:,[0,1,2,3,4,5,6,11]]\n",
    "yields_maize_2017_rabi_agg = yields_maize_2017_rabi_agg.rename(columns = {'Average Yield(Kg/Ha)_x': 'Average Yield(Kg/Ha)', 'geometry_x': 'geometry'})\n",
    "yields_maize_2017_rabi_agg  = gpd.GeoDataFrame(yields_maize_2017_rabi_agg , geometry = yields_maize_2017_rabi_agg.geometry, crs = {'init': 'epsg:4326'})\n",
    "yields_maize_2017_rabi_agg = yields_maize_2017_rabi_agg.drop_duplicates(ignore_index=True)#subset = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk', ''], ignore_index=True)\n",
    "\n",
    "yields_maize_2017_kharif_agg = yields_maize_2017_kharif_agg.merge(yields_maize_2017_kharif, how = 'inner', on = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])\n",
    "yields_maize_2017_kharif_agg = yields_maize_2017_kharif_agg.iloc[:,[0,1,2,3,4,5,6,11]]\n",
    "yields_maize_2017_kharif_agg = yields_maize_2017_kharif_agg.rename(columns = {'Average Yield(Kg/Ha)_x': 'Average Yield(Kg/Ha)', 'geometry_x': 'geometry'})\n",
    "yields_maize_2017_kharif_agg  = gpd.GeoDataFrame(yields_maize_2017_kharif_agg, geometry = yields_maize_2017_kharif_agg.geometry, crs = {'init': 'epsg:4326'})\n",
    "yields_maize_2017_kharif_agg = yields_maize_2017_kharif_agg.drop_duplicates(ignore_index=True)#subset = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk', ''], ignore_index=True)\n",
    "\n",
    "yields_maize_2017_zaid_agg = yields_maize_2017_zaid_agg.merge(yields_maize_2017_zaid, how = 'inner', on = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])\n",
    "yields_maize_2017_zaid_agg = yields_maize_2017_zaid_agg.iloc[:,[0,1,2,3,4,5,6,11]]\n",
    "yields_maize_2017_zaid_agg = yields_maize_2017_zaid_agg.rename(columns = {'Average Yield(Kg/Ha)_x': 'Average Yield(Kg/Ha)', 'geometry_x': 'geometry'})\n",
    "yields_maize_2017_zaid_agg  = gpd.GeoDataFrame(yields_maize_2017_zaid_agg , geometry = yields_maize_2017_zaid_agg.geometry, crs = {'init': 'epsg:4326'})\n",
    "yields_maize_2017_zaid_agg = yields_maize_2017_zaid_agg.drop_duplicates(ignore_index=True)#subset = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk', ''], ignore_index=True)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\pyproj\\crs\\crs.py:130: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\pyproj\\crs\\crs.py:130: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\pyproj\\crs\\crs.py:130: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    }
   ],
   "source": [
    "yields_maize_2018_rabi_agg = yields_maize_2018_rabi_agg.merge(yields_maize_2018_rabi, how = 'inner', on = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])\n",
    "yields_maize_2018_rabi_agg = yields_maize_2018_rabi_agg.iloc[:,[0,1,2,3,4,5,6,11]]\n",
    "yields_maize_2018_rabi_agg = yields_maize_2018_rabi_agg.rename(columns = {'Average Yield(Kg/Ha)_x': 'Average Yield(Kg/Ha)', 'geometry_x': 'geometry'})\n",
    "yields_maize_2018_rabi_agg  = gpd.GeoDataFrame(yields_maize_2018_rabi_agg , geometry = yields_maize_2018_rabi_agg.geometry, crs = {'init': 'epsg:4326'})\n",
    "yields_maize_2018_rabi_agg = yields_maize_2018_rabi_agg.drop_duplicates(ignore_index=True)#subset = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk', ''], ignore_index=True)\n",
    "\n",
    "yields_maize_2018_kharif_agg = yields_maize_2018_kharif_agg.merge(yields_maize_2018_kharif, how = 'inner', on = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])\n",
    "yields_maize_2018_kharif_agg = yields_maize_2018_kharif_agg.iloc[:,[0,1,2,3,4,5,6,11]]\n",
    "yields_maize_2018_kharif_agg = yields_maize_2018_kharif_agg.rename(columns = {'Average Yield(Kg/Ha)_x': 'Average Yield(Kg/Ha)', 'geometry_x': 'geometry'})\n",
    "yields_maize_2018_kharif_agg  = gpd.GeoDataFrame(yields_maize_2018_kharif_agg , geometry = yields_maize_2018_kharif_agg.geometry, crs = {'init': 'epsg:4326'})\n",
    "yields_maize_2018_kharif_agg = yields_maize_2018_kharif_agg.drop_duplicates(ignore_index=True)#subset = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk', ''], ignore_index=True)\n",
    "\n",
    "yields_maize_2018_zaid_agg = yields_maize_2018_zaid_agg.merge(yields_maize_2018_zaid, how = 'inner', on = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk'])\n",
    "yields_maize_2018_zaid_agg = yields_maize_2018_zaid_agg.iloc[:,[0,1,2,3,4,5,6,11]]\n",
    "yields_maize_2018_zaid_agg = yields_maize_2018_zaid_agg.rename(columns = {'Average Yield(Kg/Ha)_x': 'Average Yield(Kg/Ha)', 'geometry_x': 'geometry'})\n",
    "yields_maize_2018_zaid_agg  = gpd.GeoDataFrame(yields_maize_2018_zaid_agg , geometry = yields_maize_2018_zaid_agg.geometry, crs = {'init': 'epsg:4326'})\n",
    "yields_maize_2018_zaid_agg = yields_maize_2018_zaid_agg.drop_duplicates(ignore_index=True)#subset = ['Year', 'Season', 'Insurance Unit', 'Gram Panchayat/Hobli', 'District', 'Taluk', ''], ignore_index=True)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    }
   ],
   "source": [
    "yields_maize_2016_rabi_agg.to_file(r'D:\\other_thesis\\yields_maize_2016_rabi_agg.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "yields_maize_2016_zaid_agg.to_file(r'D:\\other_thesis\\yields_maize_2016_zaid_agg.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "yields_maize_2016_kharif_agg.to_file(r'D:\\other_thesis\\yields_maize_2016_kharif_agg.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "yields_maize_2017_rabi_agg.to_file(r'D:\\other_thesis\\yields_maize_2017_rabi_agg.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "yields_maize_2017_zaid_agg.to_file(r'D:\\other_thesis\\yields_maize_2017_zaid_agg.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "yields_maize_2017_kharif_agg.to_file(r'D:\\other_thesis\\yields_maize_2017_kharif_agg.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "yields_maize_2018_rabi_agg.to_file(r'D:\\other_thesis\\yields_maize_2018_rabi_agg.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "yields_maize_2018_zaid_agg.to_file(r'D:\\other_thesis\\yields_maize_2018_zaid_agg.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "yields_maize_2018_kharif_agg.to_file(r'D:\\other_thesis\\yields_maize_2018_kharif_agg.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soiltype(geodataframe, parameter, path, statistic, method):\n",
    "    # action = True/False\n",
    "    gdf = geodataframe.copy()\n",
    "    year = geodataframe['Year'].unique()[0] # Year\n",
    "    season = geodataframe['Season'].unique()[0].lower() # Season\n",
    "\n",
    "    file_name = 'soiltype_Karnataka_' + str(year) + '.tif'\n",
    "\n",
    "    file_path = path + file_name\n",
    "    param = rasterio.open(file_path, mode = 'r')\n",
    "    # Assign raster values to a numpy nd array\n",
    "    param_array = param.read(1) # landuse corresponding to each rasterpixel, so we extracted the pixel values from the raster    \n",
    "    # NOTE: stats must be any of these ['count', 'min', 'max', 'mean', 'sum', 'std', 'median', 'majority', 'minority', 'unique', 'range', 'nodata', 'nan']\n",
    "    zonal_stat = zonal_stats(geodataframe.geometry, param_array, affine = param.transform, geojson_out = True, nodata = param.nodata, all_touched = method, stats = statistic)\n",
    "    \n",
    "    # Extracting the statistics from the list\n",
    "    for j in range(len(statistic)):\n",
    "        gdf[parameter + '_' + statistic[j]] = np.nan\n",
    "        indx = list(gdf.columns).index(parameter + '_' + statistic[j])\n",
    "        for i in range(np.size(geodataframe,0)):\n",
    "            gdf.iloc[i,indx] = zonal_stat[i]['properties'][statistic[j]]\n",
    "\n",
    "    return gdf\n",
    "# Nu alleen nog de metrics toevoegen: slope en gaan we al afnemen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "c:\\Users\\mieke\\anaconda3\\envs\\thesis_base\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    }
   ],
   "source": [
    "maize_2016_rabi = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Rabi')] # 241\n",
    "maize_2016_zaid = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Summer')] # 23\n",
    "maize_2016_kharif = obs_maize[(obs_maize['Year'] == 2016) & (obs_maize['Season'] == 'Kharif')] # 1916\n",
    "maize_2017_rabi = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Rabi')] # 251\n",
    "maize_2017_zaid = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Summer')] # 16\n",
    "maize_2017_kharif = obs_maize[(obs_maize['Year'] == 2017) & (obs_maize['Season'] == 'Kharif')] # 1760\n",
    "maize_2018_rabi = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Rabi')] # 225\n",
    "maize_2018_zaid = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Summer')] # 8\n",
    "maize_2018_kharif = obs_maize[(obs_maize['Year'] == 2018) & (obs_maize['Season'] == 'Kharif')] # 1568\n",
    "\n",
    "maize_2016_rabi = soiltype(maize_2016_rabi, 'Soiltype', 'D:/Data_download/Other/Soiltype/cropmask/', ['majority'], False)\n",
    "maize_2016_zaid = soiltype(maize_2016_zaid, 'Soiltype', 'D:/Data_download/Other/Soiltype/cropmask/', ['majority'], False)\n",
    "maize_2016_kharif = soiltype(maize_2016_kharif, 'Soiltype', 'D:/Data_download/Other/Soiltype/cropmask/', ['majority'], False)\n",
    "maize_2017_rabi = soiltype(maize_2017_rabi, 'Soiltype', 'D:/Data_download/Other/Soiltype/cropmask/', ['majority'], False)\n",
    "maize_2017_zaid = soiltype(maize_2017_zaid, 'Soiltype', 'D:/Data_download/Other/Soiltype/cropmask/', ['majority'], False)\n",
    "maize_2017_kharif = soiltype(maize_2017_kharif, 'Soiltype', 'D:/Data_download/Other/Soiltype/cropmask/', ['majority'], False)\n",
    "maize_2018_rabi = soiltype(maize_2018_rabi, 'Soiltype', 'D:/Data_download/Other/Soiltype/cropmask/', ['majority'], False)\n",
    "maize_2018_zaid = soiltype(maize_2018_zaid, 'Soiltype', 'D:/Data_download/Other/Soiltype/cropmask/', ['majority'], False)\n",
    "maize_2018_kharif = soiltype(maize_2018_kharif, 'Soiltype', 'D:/Data_download/Other/Soiltype/cropmask/', ['majority'], False)\n",
    "\n",
    "\n",
    "maize_rabi = pd.concat([maize_2016_rabi, maize_2017_rabi, maize_2018_rabi], ignore_index=True)\n",
    "maize_zaid = pd.concat([maize_2016_zaid, maize_2017_zaid, maize_2018_zaid], ignore_index=True)\n",
    "maize_kharif = pd.concat([maize_2016_kharif, maize_2017_kharif, maize_2018_kharif], ignore_index=True)\n",
    "\n",
    "maize_rabi.to_file(r'D:\\other_thesis\\maize_rabi_soiltype.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "maize_zaid.to_file(r'D:\\other_thesis\\maize_zaid_soiltype.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run\n",
    "maize_kharif.to_file(r'D:\\other_thesis\\maize_kharif_soiltype.geojson', driver=\"GeoJSON\") # Save the derived datframe as it takes a long time to run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('thesis_base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "734205a0c94b5e97d2e885f269ea6bd400da4ba9a6c87b08a93b97fdaab1acc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
